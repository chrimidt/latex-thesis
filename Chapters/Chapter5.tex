% Chapter 5: Results and Analysis

Presentation of the results, with tables, charts, and explanations for each tested method's performance.

Brief overview of the chapterâ€™s purpose.
Recap the evaluation goals (model performance across head, middle, and tail classes, and comparing methods).

\section{Overall Results}
Present the performance of all tested models and methods.
Use tables or charts to summarize key results.
Highlight trends or notable observations across the methods.

\section{Head, Middle, and Tail Class Performance}
Break down the performance into head, middle, and tail class groups.
Include visualizations.
Discuss how well the methods balance performance across these groups, particularly focusing on tail classes.

\subsection{MobileNetV2}
Table \ref{tab:mobilenet_bal_acc1_1} show the top 1 accuracies for MobileNetV2 on various loss functions.

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax   & 0.7978   & 0.8059 & 0.8069 & 0.7870 & 0.8684 \\
        Focal loss   & 0.8014   & 0.8011 & 0.7998 4 & 0.7870 & 0.8947 \\
        Weighted Softmax loss   & 0.7978   & 0.8059 & 0.8069 & 0.7870 & 0.8684 \\
        Class-balanced loss   & 0.7978   & 0.8059 & 0.8069 & 0.7870 & 0.8684 \\
        Balanced Softmax loss   & 0.8034  & 0.8030 & 0.8069 & 0.7574 & 0.9211 \\
        Equalization loss   & 0.7994   & 0.8040 & 0.8057 & 0.7692 & 0.9211 \\
        LDAM loss   &  0.7828   & 0.7821 & 0.7808 & 0.7574 & 0.9211 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for MobileNetV2 trained on the custom balanced dataset, showing Acc1.}
    \label{tab:mobilenet_bal_acc1_1}
\end{table}

Table \ref{tab:mobilenet_lt_acc1_1} show the top 1 accuracies for MobileNetV2 on various loss functions.

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax   & 0.5282   & 0.7735 & 0.8341 & 0.5917 & 0.2368 \\
        Focal loss   & 0.5200   & 0.7745 & 0.8389 & 0.5917 & 0.1579 \\
        Weighted Softmax loss   & 0.5016   & 0.7231 & 0.7808 & 0.5503 & 0.2105 \\
        Class-balanced loss   & 0.1936   & 0.0913 & 0.0521 & 0.2485 & 0.2632 \\
        Balanced Softmax loss   & 0.5796   & 0.7650 & 0.8069 & 0.6331 & 0.4211 \\
        Equalization loss   & 0.5310   & 0.7650 & 0.8235 & 0.5917 & 0.2368 \\
        LDAM loss   & 0.4264 & 0.5899 & 0.6137 & 0.5444 & 0.2632 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for MobileNetV2 trained on the long-tailed dataset showing Acc1.}
    \label{tab:mobilenet_lt_acc1_1}
\end{table}

\subsection{ResNet50V2}

Table \ref{tab:resnet_bal_acc1_1} show the top 1 accuracies for ResNet50V2 on various loss functions.

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.8324  & 0.8421 & 0.8448 & 0.8047 & 0.9474 \\
        Focal loss   & 0.8310  & 0.8344 & 0.8341 & 0.8166 & 0.9211 \\
        Weighted Softmax loss   & 0.8324 & 0.8421 & 0.8448 & 0.8047 & 0.9474 \\
        Class-balanced loss   &  0.8324 & 0.8421 & 0.8448 & 0.8047 & 0.9474 \\
        Balanced Softmax loss   & 0.8310 & 0.8430 & 0.8460 & 0.8107 & 0.9211 \\
        Equalization loss   & 0.8292 & 0.8373 & 0.8412 & 0.7929 & 0.9474 \\
        LDAM loss   & 0.7990 & 0.7983 & 0.8069 & 0.7337 & 0.8947 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ResNet50V2 trained on the custom balanced dataset, showing Acc1.}
    \label{tab:resnet_bal_acc1_1}
\end{table}

Table \ref{tab:resnet_lt_acc1_1} show the top 1 accuracies for ResNet50V2 on various loss functions.

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.5522 & 0.7954 & 0.8531 & 0.6391 & 0.2105 \\
        Focal loss   & 0.5456 & 0.7935 & 0.8483 & 0.6272 & 0.3158 \\
        Weighted Softmax loss   & 0.4976 & 0.7336 & 0.7915 & 0.5562 & 0.2368 \\
        Class-balanced loss   & 0.2052 & 0.1836 &  0.1445 & 0.3787 & 0.1842 \\
        Balanced Softmax loss   & 0.5908 & 0.7916 & 0.8270 & 0.6568 & 0.6053 \\
        Equalization loss   & 0.5452 & 0.7897 & 0.8389 & 0.6450 & 0.3421 \\
        LDAM loss   & 0.3742 & 0.5937 & 0.6469 & 0.4438 & 0.0789 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ResNet50V2 trained on the long-tailed dataset, showing Acc1.}
    \label{tab:resnet_lt_acc1_1}
\end{table}

\subsection{ViT-B/16}

Table \ref{tab:vit_bal_acc1_1} show the top 1 accuracies for ViT-B/16 on various loss functions.

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.5620 & 0.5671 & 0.5521 & 0.6036 & 0.7368 \\
        Focal loss   & 0.5516 & 0.5538 & 0.5438 & 0.5680 & 0.7105 \\
        Weighted Softmax loss   & 0.5620 & 0.5671 & 0.5521 & 0.6036 & 0.7368 \\
        Class-balanced loss   & 0.5620 & 0.5671 &  0.5521 & 0.6036 & 0.7368 \\
        Balanced Softmax loss   & 0.5628 & 0.5642 & 0.5640 & 0.5325 & 0.7105 \\
        Equalization loss   & 0.5634   & 0.5519 & 0.5462 & 0.5503 & 0.6842 \\
        LDAM loss   & 0.5906 &  0.6013 & 0.5924 & 0.6095 & 0.7632 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ViT-B/16 trained on the custom balanced dataset, showing Acc1.}
    \label{tab:vit_bal_acc1_1}
\end{table}

Table \ref{tab:vit_lt_acc1} show the top 1 accuracies for ViT-B/16 on various loss functions.

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.2254 & 0.4367 & 0.5071 & 0.1775 & 0.0263 \\
        Focal loss   & 0.2210 & 0.4206 & 0.4834 & 0.1953 & 0.0263 \\
        Weighted Softmax loss   & 0.1284 & 0.1760 & 0.1919 & 0.1302 & 0.0263 \\
        Class-balanced loss   & 0.0558 & 0.0076 & 0.0000 & 0.0237 & 0.1053 \\
        Balanced Softmax loss   & 0.2460 & 0.4244 & 0.4822 &  0.2130 & 0.0789 \\
        Equalization loss   & 0.2168 & 0.4215 & 0.4893 & 0.1716 & 0.0263 \\
        LDAM loss   & 0.5906 & 0.6013 & 0.5924 & 0.6095 & 0.7632 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ViT-B/16 trained on the long-tailed dataset, showing Acc1.}
    \label{tab:vit_lt_acc1}
\end{table}

\subsection{ConvNeXt Base}

Table \ref{tab:conv_bal_acc1_1} show the top 1 accuracies for ConvNeXt Base on various loss functions.

\begin{table}[h!]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.8332 & 0.8535 & 0.8566 & 0.8166 & 0.9474 \\
        Focal loss   & 0.8314 & 0.8487 & 0.8507 & 0.8284 & 0.8947 \\
        Weighted Softmax loss   & 0.8332 & 0.8535 & 0.8566 &  0.8166 & 0.9474 \\
        Class-balanced loss   & 0.8332 & 0.8535 & 0.8566 & 0.8166 & 0.9474 \\
        Balanced Softmax loss   & 0.8364 & 0.8344 & 0.8365 & 0.7988 & 0.9474 \\
        Equalization loss   & 0.8318 & 0.8468 & 0.8448 & 0.8343 & 0.9474 \\
        LDAM loss   & 0.8316 & 0.8373 & 0.8412 & 0.8047 & 0.8947 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ConvNeXt Base trained on the custom balanced dataset, showing Acc1.}
    \label{tab:conv_bal_acc1_1}
\end{table}

Table \ref{tab:conv_lt_acc1_1} show the top 1 accuracies for ConvNeXt Base on various loss functions.

\begin{table}[h!]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.5972 & 0.8316 & 0.8898 & 0.6568 & 0.3158 \\
        Focal loss   & 0.5938 & 0.8145 & 0.8685 & 0.6568 & 0.3158 \\
        Weighted Softmax loss   & 0.4090 & 0.6356 & 0.6848 & 0.4911 & 0.1842 \\
        Class-balanced loss   & 0.0142 & 0.0019 & 0.0000 & 0.0000 & 0.0526 \\
        Balanced Softmax loss   & 0.6460 & 0.8230 & 0.8685 & 0.6509 & 0.5789 \\
        Equalization loss   & 0.5956 & 0.8278 & 0.8768 & 0.6923 & 0.3421 \\
        LDAM loss   & 0.3770 & 0.5956 & 0.6445 & 0.4260 & 0.2632 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ConvNeXt Basetrained on the long-tailed dataset, showing Acc1.}
    \label{tab:conv_lt_acc1_1}
\end{table}

\section{Comparison of Loss Functions}
Analyze how different loss functions impact performance.
Use visualizations to compare results ( per-class performance or confusion matrices).
Discuss strengths and weaknesses of each loss function.

\section{Qualitative Results}
Optional.

Provide examples of correctly and incorrectly classified samples, especially for tail classes.
Include visualizations or images of difficult cases to highlight challenges in tail-class prediction.

% \section{Ablation Studies}
% Optional.

% If applicable, evaluate the impact of individual components or configurations (e.g., re-weighting, sampling).
% Discuss how removing or altering specific aspects affects performance.

\section{Summary and Discussion}
Recap the key findings, such as which methods or loss functions performed best and why.
Connect these findings to the thesis objectives and broader implications for long-tailed learning.