% Chapter 6: Conclusion and Future Work

The findings from the experiments conducted in this thesis underlines the difficulty of achieving strong performances with deep long-tailed learning. Specifically, the results emphasizes the importance of thoughtfully combining model architectures, loss design, and choice of configurations. Among the evaluated approaches, the Balanced Softmax Loss consistently achieved the best performance on tail classes, while maintaining a comparable performance on other categories across multiple CNN backbones. In contrast, Class-Balanced Loss underperformed across all models and categories, suggesting a fault in implementation \todo{investigate}. Likewise, ViT-B/16's performance gap from both CNN-based architectures and its own benchmark imply that vision transformer architectures may require extensive adaptations to reach their full potential.  

\section{Revisiting the Goals of the Thesis}
In revisiting the goals of this thesis, it has become clear that the investigation of the deep long-tailed learning technique \emph{Class Re-Balancing} has yielded valuable insight. The findings included that performance on tail classes often comes with a trade-off in performance on head classes. Similarly, adequate performances on all classes was often attributed to the performance on head classes and not inherently on tail classes, although the Balanced Softmax Loss convincingly overcame this challenge across CNN-based architectures. This aligns with the goal of investigating the ability of deep long-tailed learning techniques to maintain overall accuracy. 

Secondly, the evaluations of different model architectures, namely the CNN-based and Vision Transformers, in combination with different class re-balancing designs has revealed that model design has an effect on the performance of long-tailed learning, and that the MobileNetV2 architecture exhibits greater robustnes against choice of loss design than other architectues evaluated in this thesis. 

Finally, these findings contribute to a more comprehensive understanding of what to consider when training a deep network with long-tailed data, and, in doing so, serves as a guide to deep learning practitioners seeking more informed choices when encountered with a long-tailed problem.

\section{Future Work}
Future investigation would benefit from evaluating experiments with larger datasets, such as ImageNet or iNaturalist to gain more insight into the performance of models and long-tailed techniques. Additionally, training ViT-B/16 on larger datasets while carefully considering its configurations could prove its full potential. Furthermore, evaluating the LDAM including the DRW and, potentially, combined with other loss functions on CIFAR-100-LT could reveal under which conditions tail-class performance is maximized. Finally, other techniques, such as re-sampling in combination with class re-balancing, should be explored.