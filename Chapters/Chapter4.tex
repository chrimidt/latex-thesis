% Chapter 4: Experimental Setup

This chapter focuses on the on the implementation details of the experiments conducted in this thesis. Here, the specifics of the training configurations are described. 

\section{Dataset Specifications}
Details about the dataset(s) used, including size, source, and preprocessing steps.
Description of class imbalance characteristics (if applicable), and the train/validation/test splits.

\section{Data Preprocessing}
Any transformations, augmentations, or normalization applied to the dataset before feeding it to the model.
Information on how you handled class imbalance (e.g., re-sampling techniques or synthetic data generation).

\section{Model Architecture Settings}
Description of the model(s) used, including any specific architecture choices, hyperparameters, or modifications.
Brief details on why these models were chosen, especially if youâ€™re comparing multiple models.

\section{Training Configurations}
Hyperparameters, such as batch size, learning rate, optimizer type (like Adam or SGD), and regularization techniques (e.g., dropout, weight decay).
Any specific settings for handling long-tailed data, such as dynamic re-weighting, if applicable.

\section{Evaluation Metrics}
Explanation of the metrics used to assess model performance, such as accuracy, F1 score, precision, recall, or custom metrics for imbalanced datasets.
Justification for choosing each metric, especially if they help address challenges with imbalanced data.

\section{Hardware and Software Configurations}
Hardware details (e.g., number of GPUs, CPU type, memory, etc.).
Software environment, including the versions of libraries and frameworks (e.g., PyTorch, TensorFlow) used.

\section{Reproducibility Considerations}
Steps taken to ensure that results can be reproduced, such as random seed initialization and details on dataset versions.
Any scripts, configurations, or instructions for reproducing experiments.
