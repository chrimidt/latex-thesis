\chapter{Results} % Results, code, etc.
\label{app:A}
Tables of the results from training.


\section{MobileNetV2}
\textit{MobileNetV2 trained on custom balanced dataset and imbalanced dataset on different loss functions.}\\

Table \ref{tab:mobilenet_bal_acc1} show the top 1 accuracies for MobileNetV2 on various loss functions. Table \ref{tab:mobilenet_bal_results} show the loss, top 1 accuracy, and F1 score.\\
Table \ref{tab:mobilenet_lt_acc1} show the top 1 accuracies for MobileNetV2 on various loss functions. Table \ref{tab:mobilenet_lt_results} show the loss, top 1 accuracy, and F1 score. 

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax   & 0.7978   & 0.8059 & 0.8069 & 0.7870 & 0.8684 \\
        Focal loss   & 0.8014   & 0.8011 & 0.7998 4 & 0.7870 & 0.8947 \\
        Weighted Softmax loss   & 0.7978   & 0.8059 & 0.8069 & 0.7870 & 0.8684 \\
        Class-balanced loss   & 0.8008   & 0.8049 & 0.8140 & 0.7456 & 0.8684 \\
        Balanced Softmax loss   & 0.8034  & 0.8030 & 0.8069 & 0.7574 & 0.9211 \\
        Equalization loss   &  0.8078  & 0.7916 & 0.7962 & 0.7396 & 0.9211 \\
        LDAM loss   &  0.7828   & 0.7821 & 0.7808 & 0.7574 & 0.9211 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for MobileNetV2 trained on the custom balanced dataset, showing Acc1.}
    \label{tab:mobilenet_bal_acc1}
\end{table}

\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{ % Scale to text width
        \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
            \toprule
            \multirow{2}{*}{Loss Function} & \multicolumn{3}{c|}{Balanced} & \multicolumn{3}{c|}{Long-tailed} & \multicolumn{3}{c|}{Head} & \multicolumn{3}{c|}{Middle} & \multicolumn{3}{c}{Tail} \\ 
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
            & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 \\ 
            \midrule
            Softmax & 1.1455 & 0.7978 & 0.7967 & 1.1415 & 0.8059 & 0.8208 & 1.1208 & 0.8069 & 0.8587 & 1.3060 & 0.7870 & 0.8368 & 0.8690 & 0.8684 & 0.8684 \\
            Focal Loss & 0.6765 & 0.8014 & 0.8001 & 0.7063 & 0.8011 & 0.8175 & 0.7005 & 0.7998 & 0.8531 & 0.8028 & 0.7870 & 0.8293 & 0.4055 & 0.8947 & 0.8860 \\
            Weighted Softmax & 1.1455 & 0.7978 & 0.7967 & 1.1415 & 0.8059 & 0.8208 & 1.1208 & 0.8069 & 0.8587 & 1.3060 & 0.7870 & 0.8368 & 0.8690 & 0.8684 & 0.8684 \\
            Class-balanced & 0.0185 & 0.8008 & 0.7989 & 0.0194 & 0.8049 & 0.8194 & 0.0192 & 0.8140 & 0.8641 & 0.0219 & 0.7456 & 0.7980 & 0.0121 & 0.8684 & 0.8596 \\
            Balanced Softmax & 1.1289 & 0.8034 & 0.8011 & 1.1848 & 0.8030 & 0.8145 & 1.1469 & 0.8069 & 0.8553 & 1.4407 & 0.7574 & 0.8123 & 0.8872 & 0.9211 & 0.9298 \\
            Equalization & 1.1361 & 0.8078 & 0.8064 & 1.2165 & 0.7916 & 0.8092 & 1.1728 & 0.7962 & 0.8534 & 1.5540 & 0.7396 & 0.7944 & 0.6858 & 0.9211 & 0.9123 \\
            LDAM & 13.8126 &  0.7828 & 0.7817 & 13.5566 & 0.7821 & 0.7955 & 13.6884 & 0.7808 & 0.8325 & 14.7496 & 0.7574 & 0.8016 & 5.3231 & 0.9211 & 0.9035 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Evaluation results for MobileNetV2 trained on the custom balanced dataset, showing Loss, Acc1, and F1 scores for each dataset split.}
    \label{tab:mobilenet_bal_results}
\end{table}



\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax   & 0.5282   & 0.7735 & 0.8341 & 0.5917 & 0.2368 \\
        Focal loss   & 0.5200   & 0.7745 & 0.8389 & 0.5917 & 0.1579 \\
        Weighted Softmax loss   & 0.5016   & 0.7231 & 0.7808 & 0.5503 & 0.2105 \\
        Class-balanced loss   &  0.5034  & 0.7336 & 0.7938 & 0.5385 & 0.2632 \\
        Balanced Softmax loss   & 0.5796   & 0.7650 & 0.8069 & 0.6331 & 0.4211 \\
        Equalization loss   &   0.0618 & 0.0647 & 0.0675 & 0.0592 & 0.0263 \\
        LDAM loss   & 0.4264 & 0.5899 & 0.6137 & 0.5444 & 0.2632 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for MobileNetV2 trained on the long-tailed dataset showing Acc1.}
    \label{tab:mobilenet_lt_acc1}
\end{table}

\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{ % Scale to text width
        \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
            \toprule
            \multirow{2}{*}{Loss Function} & \multicolumn{3}{c|}{Balanced} & \multicolumn{3}{c|}{Long-tailed} & \multicolumn{3}{c|}{Head} & \multicolumn{3}{c|}{Middle} & \multicolumn{3}{c}{Tail} \\ 
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
            & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 \\ 
            \midrule
            Softmax & 3.2503 & 0.5282 & 0.4884 & 1.2212 & 0.7735 & 0.7578 & 0.8136 & 0.8341 & 0.8492 & 2.4604 & 0.5917 & 0.6444 & 4.7629 & 0.2368 & 0.2544 \\
            Focal Loss & 2.3526 & 0.5200 & 0.4818 & 0.8022 & 0.7745 & 0.7602 & 0.5177 & 0.8389 & 0.8528 & 1.5864 & 0.5917 & 0.6625 & 3.6343 & 0.1579 & 0.1667 \\
            Weighted Softmax & 3.1412 & 0.5016 & 0.4690 & 1.2817 & 0.7231 & 0.7104 & 0.8786 & 0.7808 & 0.8015 & 2.3365 & 0.5503 & 0.6213 & 5.1836 & 0.2105 & 0.1912 \\
            Class-balanced & 0.0722 & 0.5034 & 0.4702 & 0.0093 & 0.7336 & 0.7211 & 0.0013 & 0.7938 & 0.8103 & 0.0140 & 0.5385 & 0.6047 & 0.1658 & 0.2632 & 0.2807 \\
            Balanced Softmax & 3.1185 & 0.5796 & 0.5572 & 1.1630 & 0.7650 & 0.7685 & 0.7989 & 0.8069 & 0.8422 & 2.1612 & 0.6331 & 0.6872 & 4.8108 & 0.4211 & 0.4123 \\
            Equalization & 2.9106 & 0.0618 & 0.0760 & 1.1314 & 0.0647 & 0.1060 & 0.7462 & 0.0675 & 0.1157 & 2.3812 & 0.0592 & 0.0838 & 4.1272 & 0.0263 & 0.0016 \\
            LDAM & 21.4896 & 0.4264 & 0.3980 & 7.9893 & 0.5899 & 0.5909 & 5.6756 & 0.6137 & 0.6581 & 10.3379 & 0.5444 & 0.6121 & 49.1197 & 0.2632 & 0.2895 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Evaluation results for MobileNetV2 trained on the long-tailed dataset, showing Loss, Acc1, and F1 scores for each dataset split.}
    \label{tab:mobilenet_lt_results}
\end{table}




\section{ResNet50V2}
\textit{ResNet50V2 trained on custom balanced dataset and imbalanced dataset on different loss functions.}\\

Table \ref{tab:resnet_bal_acc1} show the top 1 accuracies for ResNet50V2 on various loss functions. Table \ref{tab:resnet_bal_results} show the loss, top 1 accuracy, and F1 score.\\

Table \ref{tab:resnet_lt_acc1} show the top 1 accuracies for ResNet50V2 on various loss functions. Table \ref{tab:resnet_lt_results} show the loss, top 1 accuracy, and F1 score. 

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.8324  & 0.8421 & 0.8448 & 0.8047 & 0.9474 \\
        Focal loss   & 0.8310  & 0.8344 & 0.8341 & 0.8166 & 0.9211 \\
        Weighted Softmax loss   & 0.8324 & 0.8421 & 0.8448 & 0.8047 & 0.9474 \\
        Class-balanced loss   &  0.8144 & 0.8173 & 0.8199 & 0.7751 & 0.9474 \\
        Balanced Softmax loss   & 0.8310 & 0.8430 & 0.8460 & 0.8107 & 0.9211 \\
        Equalization loss   & 0.8316 & 0.8354 & 0.8365 & 0.8166 & 0.8947 \\
        LDAM loss   & 0.7990 & 0.7983 & 0.8069 & 0.7337 & 0.8947 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ResNet50V2 trained on the custom balanced dataset, showing Acc1.}
    \label{tab:resnet_bal_acc1}
\end{table}

\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{ % Scale to text width
        \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
            \toprule
            \multirow{2}{*}{Loss Function} & \multicolumn{3}{c|}{Balanced} & \multicolumn{3}{c|}{Long-tailed} & \multicolumn{3}{c|}{Head} & \multicolumn{3}{c|}{Middle} & \multicolumn{3}{c}{Tail} \\ 
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
            & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 \\ 
            \midrule
            Softmax & 0.9823 & 0.8324 & 0.8310 & 0.9874 & 0.8421 & 0.8520 & 0.9917 & 0.8448 & 0.8860 & 1.0934 & 0.8047 & 0.8467 & 0.4205 & 0.9474 & 0.9386 \\
            Focal Loss & 0.5627 & 0.8310 & 0.8300 & 0.5578 & 0.8344 & 0.8474 & 0.5555 & 0.8341 & 0.8788 & 0.6294 & 0.8166 & 0.8607 & 0.2920 & 0.9211 & 0.9123 \\
            Weighted Softmax & 0.9823 & 0.8324 & 0.8310 & 0.9874 & 0.8421 & 0.8520 & 0.9917 & 0.8448 & 0.8860 & 1.0934 & 0.8047 & 0.8467 & 0.4205 & 0.9474 & 0.9386 \\
            Class-balanced & 0.0170 & 0.8144  & 0.8131 & 0.0167 & 0.8173 & 0.8268 & 0.0171 & 0.8199 & 0.8646 & 0.0167 & 0.7751 & 0.8193 & 0.0078 & 0.9474 & 0.9386 \\
            Balanced Softmax & 1.0198 & 0.8310 & 0.8301 & 0.9689 & 0.8430 & 0.8549 & 0.9601 & 0.8460 & 0.8893 & 1.1309 & 0.8107 & 0.8539 & 0.4440 & 0.9211 & 0.9123 \\
            Equalization & 0.9930 & 0.8316 & 0.8304 & 1.0158 & 0.8354 & 0.8496 & 1.0011 & 0.8365 & 0.8867 & 1.1822 & 0.8166 & 0.8737 & 0.5999 & 0.8947 & 0.9035 \\
            LDAM & 9.8339 & 0.7990 & 0.7979 & 10.1092 & 0.7983 & 0.8119 & 9.8723 & 0.8069 & 0.8596 & 12.5229 & 0.7337 & 0.7823 & 4.6362 & 0.8947 & 0.8772 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Evaluation results for ResNet50V2 trained on the custom balanced dataset, showing Loss, Acc1, and F1 scores for each dataset split.}
    \label{tab:resnet_bal_results}
\end{table}



\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.5522 & 0.7954 & 0.8531 & 0.6391 & 0.2105 \\
        Focal loss   & 0.5456 & 0.7935 & 0.8483 & 0.6272 & 0.3158 \\
        Weighted Softmax loss   & 0.4976 & 0.7336 & 0.7915 & 0.5562 & 0.2368 \\
        Class-balanced loss   & 0.4970 & 0.7450 & 0.8069 & 0.5562 & 0.2105 \\
        Balanced Softmax loss   & 0.5908 & 0.7916 & 0.8270 & 0.6568 & 0.6053 \\
        Equalization loss   & 0.0886 & 0.1399 & 0.1505 & 0.1124 &  0.0263 \\
        LDAM loss   & 0.3742 & 0.5937 & 0.6469 & 0.4438 & 0.0789 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ResNet50V2 trained on the long-tailed dataset, showing Acc1.}
    \label{tab:resnet_lt_acc1}
\end{table}

\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{ % Scale to text width
        \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
            \toprule
            \multirow{2}{*}{Loss Function} & \multicolumn{3}{c|}{Balanced} & \multicolumn{3}{c|}{Long-tailed} & \multicolumn{3}{c|}{Head} & \multicolumn{3}{c|}{Middle} & \multicolumn{3}{c}{Tail} \\ 
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
            & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 \\ 
            \midrule
            Softmax & 3.0907 & 0.5522 & 0.5138 & 1.0524 & 0.7954 & 0.7798 & 0.6888 & 0.8531 & 0.8654 & 2.0330 & 0.6391 & 0.6996 & 4.7658 & 0.2105 & 0.2018 \\
            Focal Loss & 2.0718 & 0.5456 & 0.5089 & 0.6284 & 0.7935 & 0.7789 & 0.3983 & 0.8483 & 0.8583 & 1.3258 & 0.6272 & 0.7054 & 2.6364 & 0.3158 & 0.3158 \\
            Weighted Softmax & 3.7904 & 0.4976 & 0.4591 & 1.3481 & 0.7336 & 0.7198 & 0.8630 & 0.7915 & 0.8098 & 2.2625 & 0.5562 & 0.6209 & 6.9808 & 0.2368 & 0.2456 \\
            Class-balanced & 0.0886 & 0.4970 & 0.4582 & 0.0107 & 0.7450 & 0.7338 & 0.0013 & 0.8069 & 0.8267 & 0.0151 & 0.5562 & 0.6380 & 0.2010 & 0.2105 & 0.2000 \\
            Balanced Softmax & 3.1081 & 0.5908 & 0.5654 & 1.0452 & 0.7916 & 0.7895 & 0.6873 & 0.8270 & 0.8602 & 2.3422 & 0.6568 & 0.7135 & 3.2275 & 0.6053 & 0.5965 \\
            Equalization & 3.0110 & 0.0886 & 0.1243 & 1.0483 & 0.1399 & 0.2187 & 0.7537 & 0.1505 & 0.2407 & 1.9859 & 0.1124 & 0.1581 & 3.4232 &  0.0263 & 0.0013 \\
            LDAM & 22.7933 & 0.3742 & 0.3337 & 8.2056 & 0.5937 & 0.5784 & 5.3320 & 0.6469 & 0.6680 & 12.3074 & 0.4438 & 0.5450 & 53.4080 & 0.0789 & 0.0789 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Evaluation results for ResNet50V2 trained on the long-tailed dataset, showing Loss, Acc1, and F1 scores for each dataset split.}
    \label{tab:resnet_lt_results}
\end{table}



\section{ViT-B/16}
\textit{ViT-B/16 trained on custom balanced dataset and imbalanced dataset on different loss functions.}\\


Table \ref{tab:vit_bal_acc1} show the top 1 accuracies for ViT-B/16 on various loss functions. Table \ref{tab:vit_bal_results} show the loss, top 1 accuracy, and F1 score.\\

Table \ref{tab:vil_lt_acc1} show the top 1 accuracies for ViT-B/16 on various loss functions. Table \ref{tab:vit_lt_results} show the loss, top 1 accuracy, and F1 score.

\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.5620 & 0.5671 & 0.5521 & 0.6036 & 0.7368 \\
        Focal loss   & 0.5516 & 0.5538 & 0.5438 & 0.5680 & 0.7105 \\
        Weighted Softmax loss   & 0.5620 & 0.5671 & 0.5521 & 0.6036 & 0.7368 \\
        Class-balanced loss   & 0.5432 & 0.5452 & 0.5427 & 0.5207 & 0.7105 \\
        Balanced Softmax loss   & 0.5628 & 0.5642 & 0.5640 & 0.5325 & 0.7105 \\
        Equalization loss   & 0.5582 & 0.5547 & 0.5462 & 0.5680 & 0.6842 \\
        LDAM loss   & 0.5906 &  0.6013 & 0.5924 & 0.6095 & 0.7632 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ViT-B/16 trained on the custom balanced dataset, showing Acc1.}
    \label{tab:vit_bal_acc1}
\end{table}

\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{ % Scale to text width
        \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
            \toprule
            \multirow{2}{*}{Loss Function} & \multicolumn{3}{c|}{Balanced} & \multicolumn{3}{c|}{Long-tailed} & \multicolumn{3}{c|}{Head} & \multicolumn{3}{c|}{Middle} & \multicolumn{3}{c}{Tail} \\ 
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
            & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 \\ 
            \midrule
            Softmax & 4.6431 & 0.5620 & 0.5593 & 4.6089 & 0.5671 & 0.5951 & 4.6420 & 0.5521 & 0.6367 & 4.7263 & 0.6036 & 0.6648 & 3.3521 & 0.7368 & 0.7281 \\
            Focal Loss & 2.3473 & 0.5516 & 0.5488 & 2.3562 & 0.5538 & 0.5869 & 2.4288 & 0.5438 & 0.6324 & 2.2330 & 0.5680 & 0.6355 & 1.2929 & 0.7105 & 0.6930 \\
            Weighted Softmax & 4.6431 & 0.5620 & 0.5593 & 4.6089 & 0.5671 & 0.5951 & 4.6420 & 0.5521 & 0.6367 & 4.7263 & 0.6036 & 0.6648 & 3.3521 & 0.7368 & 0.7281 \\
            Class-balanced & 0.0801 & 0.5432 & 0.5413 & 0.0861 & 0.5452 & 0.5831 & 0.0855 & 0.5427 & 0.6342 & 0.1003 & 0.5207 & 0.5951 & 0.0365 & 0.7105 & 0.6930 \\
            Balanced Softmax & 4.7131 & 0.5628 & 0.5592 & 4.6809 & 0.5642 & 0.5929 & 4.7739 & 0.5640 & 0.6471 & 4.8161 & 0.5325 & 0.5998 & 2.0138 & 0.7105 & 0.7105 \\
            Equalization & 4.5834 & 0.5582 & 0.5547 & 4.6640 & 0.5547 & 0.5853 & 4.7238 & 0.5462 & 0.6334 & 4.8802 & 0.5680 & 0.6344 & 2.3729 & 0.6842 & 0.6842 \\
            LDAM &  48.2745 & 0.5906 & 0.5926 & 47.4149 &  0.6013 & 0.6348 & 49.6692 & 0.5924 & 0.6790 & 42.0117 & 0.6095 & 0.6780 & 21.3751 & 0.7632 & 0.7281 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Evaluation results for ViT-B/16 trained on the custom balanced dataset, showing Loss, Acc1, and F1 scores for each dataset split.}
    \label{tab:vit_bal_results}
\end{table}



\begin{table}[H]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.2254 & 0.4367 & 0.5071 & 0.1775 & 0.0263 \\
        Focal loss   & 0.2210 & 0.4206 & 0.4834 & 0.1953 & 0.0263 \\
        Weighted Softmax loss   & 0.1284 & 0.1760 & 0.1919 & 0.1302 & 0.0263 \\
        Class-balanced loss   & 0.1346 & 0.1865 & 0.2014 & 0.1361 & 0.0789 \\
        Balanced Softmax loss   & 0.2460 & 0.4244 & 0.4822 &  0.2130 & 0.0789 \\
        Equalization loss   & 0.1686 & 0.2778 & 0.3140 & 0.1361 & 0.1053 \\
        LDAM loss   & 0.1570 & 0.2750 & 0.3140 & 0.1361 & 0.0263 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ViT-B/16 trained on the long-tailed dataset, showing Acc1.}
    \label{tab:vil_lt_acc1}
\end{table}


\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{ % Scale to text width
        \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
            \toprule
            \multirow{2}{*}{Loss Function} & \multicolumn{3}{c|}{Balanced} & \multicolumn{3}{c|}{Long-tailed} & \multicolumn{3}{c|}{Head} & \multicolumn{3}{c|}{Middle} & \multicolumn{3}{c}{Tail} \\ 
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
            & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 \\ 
            \midrule
            Softmax & 13.5272 & 0.2254 & 0.1871 & 6.7999 & 0.4367 & 0.4216 & 5.3024 & 0.5071 & 0.5248 & 11.3663 & 0.1775 & 0.2303 & 19.7511 & 0.0263 & 0.0263 \\
            Focal Loss & 7.5701 & 0.2210 & 0.1850 & 3.6474 & 0.4206 & 0.4016 & 2.8064 & 0.4834 & 0.4914 & 6.1246 & 0.1953 & 0.2666 & 11.3091 & 0.0263 & 0.0263 \\
            Weighted Softmax & 6.5391 & 0.1284 & 0.1144 & 3.9782 & 0.1760 & 0.1902 & 3.4559 & 0.1919 & 0.2357 & 4.7288 & 0.1302 & 0.1541 & 11.0975 & 0.0263 & 0.0351 \\
            Class-balanced & 0.1250 & 0.1346 & 0.1222 & 0.0174 & 0.1865 & 0.2012 & 0.0038 & 0.2014 & 0.2461 & 0.0219 & 0.1361 & 0.1738 & 0.2991 & 0.0789 & 0.0965 \\
            Balanced Softmax & 13.3583 & 0.2460 & 0.2123 & 6.7016 & 0.4244 & 0.4175 & 5.2929 & 0.4822 & 0.5121 & 11.3472 & 0.2130 & 0.2710 & 17.3287 & 0.0789 & 0.0877 \\
            Equalization & 13.0306 & 0.1686 & 0.1643 & 6.7630 & 0.2778 & 0.3268 & 5.1423 & 0.3140 & 0.3924 & 12.4673 & 0.1361 & 0.1832 & 17.3896 & 0.1053 & 0.0755 \\
            LDAM & 43.5990 & 0.1570 & 0.1321 & 17.1295 & 0.2750 & 0.2769 & 11.5903 & 0.3140 & 0.3466 & 30.5370 & 0.1361 & 0.1791 & 80.9656 & 0.0263 & 0.0351 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Evaluation results for ViT-B/16 trained on the long-tailed dataset, showing Loss, Acc1, and F1 scores for each dataset split.}
    \label{tab:vit_lt_results}
\end{table}



\section{ConvNeXt Base}
\textit{ConvNeXt Base trained on custom balanced dataset and imbalanced dataset on different loss functions.}\\


Table \ref{tab:conv_bal_acc1} show the top 1 accuracies for ConvNeXt Base on various loss functions. Table \ref{tab:conv_bal_results} show the loss, top 1 accuracy, and F1 score.\\

Table \ref{tab:conv_lt_acc1} show the top 1 accuracies for ConvNeXt Base on various loss functions. Table \ref{tab:conv_lt_results} show the loss, top 1 accuracy, and F1 score.

\begin{table}[h!]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.8332 & 0.8535 & 0.8566 & 0.8166 & 0.9474 \\
        Focal loss   & 0.8314 & 0.8487 & 0.8507 & 0.8284 & 0.8947 \\
        Weighted Softmax loss   & 0.8332 & 0.8535 & 0.8566 &  0.8166 & 0.9474 \\
        Class-balanced loss   & 0.8398 & 0.8344 & 0.8389 & 0.7929 & 0.9211 \\
        Balanced Softmax loss   & 0.8364 & 0.8344 & 0.8365 & 0.7988 & 0.9474 \\
        Equalization loss   & 0.8322 & 0.8392 & 0.8412 & 0.8107 & 0.9211 \\
        LDAM loss   & 0.8316 & 0.8373 & 0.8412 & 0.8047 & 0.8947 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ConvNeXt Base trained on the custom balanced dataset, showing Acc1.}
    \label{tab:conv_bal_acc1}
\end{table}

\begin{table}[h!]
    \centering
    \resizebox{\textwidth}{!}{ % Scale to text width
        \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
            \toprule
            \multirow{2}{*}{Loss Function} & \multicolumn{3}{c|}{Balanced} & \multicolumn{3}{c|}{Long-tailed} & \multicolumn{3}{c|}{Head} & \multicolumn{3}{c|}{Middle} & \multicolumn{3}{c}{Tail} \\ 
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
            & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 \\ 
            \midrule
            Softmax & 0.9904 & 0.8332 & 0.8323 & 0.9594 & 0.8535 & 0.8661 & 0.9571 & 0.8566 & 0.9010 & 1.1028 & 0.8166 & 0.8603 & 0.3731 & 0.9474 & 0.9386 \\
            Focal Loss & 0.5686 & 0.8314 & 0.8301 & 0.5597 & 0.8487 & 0.8608 & 0.5640 & 0.8507 & 0.8975 & 0.6046 & 0.8284 & 0.8730 & 0.2629 & 0.8947 & 0.8947 \\
            Weighted Softmax & 0.9904 & 0.8332 & 0.8323 & 0.9594 & 0.8535 & 0.8661 & 0.9571 & 0.8566 & 0.9010 & 1.1028 &  0.8166 & 0.8603 & 0.3731 & 0.9474 & 0.9386 \\
            Class-balanced & 0.0167 & 0.8398 & 0.8385 & 0.0163 & 0.8344 & 0.8465 & 0.0158 & 0.8389 & 0.8879 & 0.0212 & 0.7929 & 0.8349 & 0.0072 & 0.9211 & 0.9211 \\
            Balanced Softmax & 1.0008 & 0.8364 & 0.8350 & 0.9829 & 0.8344 & 0.8478 & 0.9720 & 0.8365 & 0.8853 & 1.1509 & 0.7988 & 0.8418 & 0.4780 & 0.9474 & 0.9386 \\
            Equalization & 1.0307 & 0.8322 & 0.8311 & 1.0460 & 0.8392 & 0.8539 & 0.9895 & 0.8412 & 0.8882 & 1.4433 & 0.8107 & 0.8596 & 0.5339 & 0.9211 & 0.9105 \\
            LDAM & 12.2036 & 0.8316 & 0.8308 & 11.0787 & 0.8373 & 0.8485 & 10.9948 & 0.8412 & 0.8882 & 12.5744 & 0.8047 & 0.8592 & 6.2892 & 0.8947 & 0.8947 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Evaluation results for ConvNeXt Base trained on the custom balanced dataset, showing Loss, Acc1, and F1 scores for each dataset split.}
    \label{tab:conv_bal_results}
\end{table}



\begin{table}[h!]
    \centering
    \begin{tabular}{cccccc}
        \toprule
        Loss Function & Balanced & Long-tailed & Head & Middle & Tail \\ 
        \midrule
        Softmax loss   & 0.5972 & 0.8316 & 0.8898 & 0.6568 & 0.3158 \\
        Focal loss   & 0.5938 & 0.8145 & 0.8685 & 0.6568 & 0.3158 \\
        Weighted Softmax loss   & 0.4090 & 0.6356 & 0.6848 & 0.4911 & 0.1842 \\
        Class-balanced loss   & 0.3436 & 0.5756 & 0.6469 & 0.3254 & 0.1053 \\
        Balanced Softmax loss   & 0.6460 & 0.8230 & 0.8685 & 0.6509 & 0.5789 \\
        Equalization loss   & 0.5948 & 0.7973 & 0.8460 & 0.6272 & 0.4737 \\
        LDAM loss   & 0.3770 & 0.5956 & 0.6445 & 0.4260 & 0.2632 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation results for ConvNeXt Basetrained on the long-tailed dataset, showing Acc1.}
    \label{tab:conv_lt_acc1}
\end{table}

\begin{table}[h!]
    \centering
    \resizebox{\textwidth}{!}{ % Scale to text width
        \begin{tabular}{c|ccc|ccc|ccc|ccc|ccc}
            \toprule
            \multirow{2}{*}{Loss Function} & \multicolumn{3}{c|}{Balanced} & \multicolumn{3}{c|}{Long-tailed} & \multicolumn{3}{c|}{Head} & \multicolumn{3}{c|}{Middle} & \multicolumn{3}{c}{Tail} \\ 
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16}
            & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 & Loss & Acc1 & F1 \\ 
            \midrule
            Softmax & 2.7006 & 0.5972 & 0.5645 & 0.9552 & 0.8316 & 0.8202 & 0.5867 & 0.8898 & 0.9013 & 2.1181 & 0.6568 & 0.7177 & 3.9670 & 0.3158 & 0.3158 \\
            Focal Loss & 1.8210 & 0.5938 & 0.5615 & 0.6024 & 0.8145 & 0.8002 & 0.3485 & 0.8685 & 0.8791 & 1.3247 & 0.6568 & 0.7197 & 3.0291 & 0.3158 & 0.3070 \\
            Weighted Softmax & 4.5284 & 0.4090 & 0.3763 & 2.0092 & 0.6356 & 0.6266 & 1.5444 & 0.6848 & 0.7054 & 3.1309 & 0.4911 & 0.5827 & 6.0533 & 0.1842 & 0.1930 \\
            Class-balanced & 0.1091 & 0.3436 & 0.3096 & 0.0138 & 0.5756 & 0.5595 & 0.0024 & 0.6469 & 0.6650 & 0.0221 & 0.3254 & 0.4116 & 0.2302 & 0.1053 & 0.1053 \\
            Balanced Softmax & 2.6574 & 0.6460 & 0.6273 & 0.9120 & 0.8230 & 0.8237 & 0.5457 & 0.8685 & 0.8952 & 2.1945 & 0.6509 & 0.7250 & 3.3453 & 0.5789 & 0.5965 \\
            Equalization & 2.4389 & 0.5948 & 0.5661 & 0.8748 & 0.7973 & 0.8028 & 0.5109 & 0.8460 & 0.8714 & 2.1520 & 0.6272 & 0.6963 & 3.2784 & 0.4737 & 0.4474 \\
            LDAM & 39.0426 & 0.3770 & 0.3448 & 12.8480 & 0.5956 & 0.5812 & 8.3491 & 0.6445 & 0.6597 & 25.5813 & 0.4260 & 0.5105 & 72.0081 & 0.2632 & 0.2719 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Evaluation results for ConvNeXt Base trained on the long-tailed dataset, showing Loss, Acc1, and F1 scores for each dataset split.}
    \label{tab:conv_lt_results}
\end{table}




