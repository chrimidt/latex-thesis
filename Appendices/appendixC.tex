\chapter{Experimental Setup Details}
\section{Dataset Specifications}
\label{app:data_spec}
Table \ref{tab:dataset_specs} provides an overview of the dataset splits used in this thesis. The training set consists of 45,000 samples, with 450 samples per class, generated by splitting the original CIFAR-100 training set into training and test sets. The test set derived from the split consists of 5,000 samples, with 50 samples per class. The validation set, unaltered from the original CIFAR-100 test set, contains 10,000 samples with an equal distribution of 100 samples per class.

To simulate real-world class imbalance scenarios, an exponential imbalance was introduced into the training and test sets. The imbalance factor (\(\text{imb\_factor}\)) was set to 0.01, resulting in a significant reduction of samples for the least frequent classes. Table \ref{tab:imbalance_specs} provides a summary of the imbalance characteristics.

Additionally, the imbalanced test set was further divided into three subsets based on class frequencies in the training data:

\begin{itemize}
    \item \textbf{Head Test Set:} Includes the top one-third most frequent classes.
    \item \textbf{Middle Test Set:} Includes the middle one-third of classes.
    \item \textbf{Tail Test Set:} Includes the bottom one-third least frequent classes.
\end{itemize}

The sample specifics are presented in table \ref{tab:dataset_specs}.

% The class splits were determined by sorting classes based on the number of samples in the imbalanced training dataset and grouping them equally into three categories. The resulting test splits ensure that the model is evaluated on head, middle, and tail subsets, highlighting performance variations across different class frequencies.


\begin{table}[h]
    \centering
    \caption{Dataset Specifications}
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Dataset Component} & \textbf{Total Samples} & \textbf{Samples per Class} \\ \hline
    Training Set               & 45,000                & 450                        \\ \hline
    Validation Set             & 10,000                & 100 
    \\ \hline
    Test Set                   & 5,000                 & 50                         \\ \hline
    Head Test Set              & \todo{investigate}                  & Variable      
    \\ \hline
    Middle Test Set            & \todo{investigate}                  & Variable    
    \\ \hline
    Tail Test Set              & \todo{investigate}                  & Variable      
    \\ \hline
    \end{tabular}
    \label{tab:dataset_specs}
    \end{table}

\begin{table}[h]
        \centering
        \caption{Imbalance Specifications}
        \begin{tabular}{|c|l|}
        \hline
        \textbf{Aspect}             & \textbf{Details}                                         \\ \hline
        Imbalance Type              & Exponential                                             \\ \hline
        Imbalance Factor            & 0.01                                                   \\ \hline
        Training Set Distribution   & 
        \begin{tabular}[c]{@{}l@{}}
            Most frequent class: 450 samples \\ 
            Least frequent class: 4 samples
        \end{tabular} \\ \hline
        Test Set Distribution       & 
        \begin{tabular}[c]{@{}l@{}}
            Mirrors training distribution \\ 
            Ensures no class has fewer than 1 sample
        \end{tabular} \\ \hline
        \end{tabular}
        \label{tab:imbalance_specs}
\end{table}


\section{Data Preprocessing}
Table \ref{tab:data_preprocessing} summarizes the preprocessing steps applied to the training, validation, and test datasets. \todo{reference CIFAR100 statistics.}

\begin{table}[h!]
    \centering
    \caption{Data Preprocessing Steps}
    \begin{tabular}{|c|l|}
    \hline
    \textbf{Dataset}      & \textbf{Preprocessing Steps}                                                                                          \\ \hline
    \textbf{Training}     & \begin{tabular}[c]{@{}l@{}}
    \textbullet\ Resize to 224×224 pixels \\ 
    \textbullet\ Random crop to 224×224 with 4 pixels of padding \\ 
    \textbullet\ Random horizontal flip \\ 
    \textbullet\ Normalize using CIFAR-100 statistics: \\ 
    \hspace{10pt} Mean = [0.4914, 0.4822, 0.4465], \\ 
    \hspace{10pt} Std = [0.2023, 0.1994, 0.2010]
    \end{tabular} \\ \hline
    \textbf{Validation/Test} & \begin{tabular}[c]{@{}l@{}}
    \textbullet\ Resize to 224×224 pixels \\ 
    \textbullet\ Normalize using CIFAR-100 statistics: \\ 
    \hspace{10pt} Mean = [0.4914, 0.4822, 0.4465], \\ 
    \hspace{10pt} Std = [0.2023, 0.1994, 0.2010]
    \end{tabular} \\ \hline
    \end{tabular}
    \label{tab:data_preprocessing}
    \end{table}


\section{Model Architecture Settings}
Four different architectures were used: MobileNetV2, ResNet50V2, ViT-B/16, and ConvNeXt Base. All models were initialized with pretrained weights from ImageNet to leverage transfer learning. The modifications ensured that the architectures were adapted to the CIFAR-100 dataset while retaining the general features learned during pretraining.

\myindent \textbf{MobileNetV2} The MobileNetV2 architecture is pretrained on ImageNet-1K dataset, and the classifciation layer was replaced with a 100-class fully connected layer. \todo{reference}

\myindent \textbf{ResNet50V2} The ResNet50V2 architecture is pretrained on ImageNet-1K dataset, and the fc-layer is replaced with a 100-class fully connected layer. \todo{reference}

\myindent \textbf{ViT-B/16} The ViT-B/16 architecture is pretrained on the ImageNet-21K dataset and fine-tuned on the ImageNet-1K dataset \cite{huggingface2024vitbase}. The head is replaced with a 100-clas fully connected layer.

\myindent \textbf{ConvNeXt Base} The ConvNeXt Base architecture is pretrained on the ImageNet-1K dataset \cite{torchvision2024convnextbase}, and the final layer is replaced with a 100-class fully connected layer.

The specifications of the model architectures can be seen in table \ref{tab:model_settings} \todo{make this table prettier}.

\begin{table}[h]
    \centering
    \caption{Model Architecture Settings}
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Model Name}   & \textbf{Pretrained Weights}            & \textbf{Modifications for CIFAR-100}                     \\ \hline
    MobileNetV2           & \makecell[l]{\texttt{MobileNet\_V2\_Weights.} \\ \texttt{IMAGENET1K\_V1}} 
                          & \makecell[l]{Replaced classification layer \\ with a 100-class fully connected layer} \\ \hline
    ResNet50V2            & \makecell[l]{\texttt{ResNet50\_Weights.} \\ \texttt{IMAGENET1K\_V2}} 
                          & \makecell[l]{Replaced the \texttt{fc} layer \\ with a 100-class fully connected layer} \\ \hline
    ViT-B/16              & \makecell[l]{\texttt{timm vit\_base\_patch16\_224} \\ pretrained} 
                          & \makecell[l]{Replaced the \texttt{head} \\ with a 100-class fully connected layer} \\ \hline
    ConvNeXt Base         & \makecell[l]{\texttt{ConvNeXt\_Base\_Weights.} \\ \texttt{DEFAULT}} 
                          & \makecell[l]{Replaced the final layer of the \\ classifier with a 100-class fully \\ connected layer} \\ \hline
    \end{tabular}
    \label{tab:model_settings}
\end{table}


\section{Training Configurations}
This section outlines the key hyperparameters and settings used during the training and evaluation of the models.

\begin{itemize}
    \item \textbf{Optimizer}: Adam
    \item \textbf{Learning Rate}: Initial value of \texttt{0.001}.
    \item \textbf{Learning Rate Scheduler}: StepLR with a step size of \texttt{30} epochs and a decay factor of \texttt{0.1}.
    \item \textbf{Batch Size}: \texttt{128}.
    \item \textbf{Number of Epochs}: \texttt{90}.
    \item \textbf{Weight Decay}: Default value of \texttt{1e-4}.
    \item \textbf{Class Weights}: Dynamically computed based on the training dataset and passed to the loss function. \todo{Reference to Methodology section.}
    \item \textbf{Number of GPUs}: 4. See section \ref{sec:hardware_software} for specifications.
    \item \textbf{Device Setup}: Utilized \texttt{torch.nn.DataParallel} for multi-GPU training.
    \item \textbf{Checkpoint Criteria}: The best model is saved based on the highest Top-1 validation accuracy.
\end{itemize}


\section{Evaluation Metrics}
The primary metric used to evaluate model performance during validation and testing is the top-1 accuracy. Alongside, the F1 score was calculated (macro F1 for balanced datasets, and weighted F1 for imbalanced dataset) but never used for evaluation. The F1 scores for all experiments can be seen in appendix \ref{app:A}.
% The following metrics were used to evaluate model performance during validation and testing:

% \begin{itemize}
%     \item \textbf{Top-1 Accuracy}: Proportion of correct predictions across all classes.
%     \item \textbf{F1 Score}:
%     \begin{itemize}
%         \item \textbf{Macro F1}: Used for balanced datasets, e.g., validation set and balanced test set.
%         \item \textbf{Weighted F1}: Used for imbalanced datasets to account for class frequency differences.
%     \end{itemize}
%     \item \textbf{Head/Middle/Tail Class Evaluation}: 
%     \begin{itemize}
%         \item The test set was divided into three subsets: head, middle, and tail classes, based on class frequency in the training dataset.
%         \item Performance on each subset was evaluated using both:
%         \begin{itemize}
%             \item \textbf{Top-1 Accuracy}
%             \item \textbf{Weighted F1 Score}
%         \end{itemize}
%     \end{itemize}
% \end{itemize}


\section{Hardware and Software Configurations}
\label{sec:hardware_software}
The experiments were conducted on a high-performance computing system with the following hardware and software configurations:

\subsection{Hardware}
\begin{itemize}
    \item \textbf{GPUs}: 4 NVIDIA TITAN X (Pascal), each with 12 GB memory.
    \item \textbf{RAM}: 125 GiB
    \item \textbf{Swap Space}: 63 GiB
    \item \textbf{CUDA Version}: 12.4
    \item \textbf{Driver Version}: 550.90.07
\end{itemize}

\subsection{Software}
\begin{itemize}
    \item \textbf{Operating System}: Ubuntu 22.04.4 LTS (Jammy Jellyfish)
    \item \textbf{Python Version}: 3.11.8
    \item \textbf{Deep Learning Frameworks and Libraries Versions}:
    \begin{itemize}
        \item PyTorch (\(\geq\)1.7)
        \item Torchvision (\(\geq\)0.8.0)
        % \item Timm
        \item Tensorboard (\(\geq\)1.14)
        % \item TensorboardX
    \end{itemize}
    % \item \textbf{Supporting Libraries}:
    % \begin{itemize}
    %     \item Numpy
    %     \item Pandas
    %     \item Scikit-learn
    %     \item H5py
    %     \item Pyyaml
    %     \item Matplotlib
    %     \item Tqdm
    %     \item Yacs
    % \end{itemize}
\end{itemize}



\section{Reproducibility Considerations}
To ensure that the experiments conducted in this thesis are reproducible, the following measures were implemented:

\begin{itemize}
    \item \textbf{Random Seed}: 
    \begin{itemize}
        \item A fixed random seed of \texttt{42} was used for all experiments to ensure consistent initialization across runs.
        \item Randomness was controlled for:
        \begin{itemize}
            \item Python's \texttt{random} library.
            \item NumPy (\texttt{np.random.seed}).
            \item PyTorch (\texttt{torch.manual\_seed} and \texttt{torch.cuda.manual\_seed}).
        \end{itemize}
        \item \texttt{cudnn.deterministic} was set to \texttt{True} to enforce deterministic behavior in GPU computations.
    \end{itemize}
    \item \textbf{Configuration Management}:
    \begin{itemize}
        \item All hyperparameters, dataset settings, and model configurations were defined in YAML configuration files.
        \item This allows for the exact replication of experiments by reusing the configuration files.
    \end{itemize}
    \item \textbf{Saved Artifacts}:
    \begin{itemize}
        \item Datasets were saved, making them accessible for evaluation or reuse in future experiments.
        \item Model checkpoints were saved after achieving the best validation accuracy.
    \end{itemize}
    % \item \textbf{Environment Details}:
    % \begin{itemize}
    %     \item All library versions, operating system details, and hardware configurations were documented to ensure reproducibility.
    %     \item The complete list of Python dependencies is provided in the project’s documentation.
    % \end{itemize}
\end{itemize}

\section{Implementation Faults}
\todo{Revisit this section later on.}

\begin{itemize}
    \item The wrong version of the ViT-B/16 architecture might have implemented. The version implemented is the vit-base-patch16-224  \cite{huggingface2024vitbase}  via timm which was pretrained on the ImageNet-21K and later fine-tuned on ImageNet-1K, whereas the other models are pretrained solely on the ImageNet-1K. The version on ViT-B/16 that is pretrained on the ImageNet-1K can be implemented as the torchvision version\ vit\_b\_16 \cite{torchvision2024vitb16}.
    \item Class-Balanced Loss.
\end{itemize}