% Main article - check
@misc{zhang2023deep,
      title={Deep Long-Tailed Learning: A Survey}, 
      author={Yifan Zhang and Bingyi Kang and Bryan Hooi and Shuicheng Yan and Jiashi Feng},
      year={2023},
      eprint={2110.04596},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2110.04596}, 
}

% Background Theory - check
@book{zhang2023dive,
    title={Dive into Deep Learning},
    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
    publisher={Cambridge University Press [Online]},
    note={\url{https://D2L.ai}},
    year={2023}
}

% Background Theory - check
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

% Online Course - check
@misc{cs231n,
    author = {Chaitanya Asawa, X. L.},
    title = {Cs231n: Convolutional neural networks for visual recognition},
    howpublished = {Stanford, [Online]},
    year = {},
    note = {Available: \url{http://cs231n.github.io/}}
}


% Gradients
@ARTICLE{279181,
  author={Bengio, Y. and Simard, P. and Frasconi, P.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Learning long-term dependencies with gradient descent is difficult}, 
  year={1994},
  volume={5},
  number={2},
  pages={157-166},
  doi={10.1109/72.279181}
}

% Logits
@misc{arora2024logits,
  author       = {wandb.ai},
  title        = {Understanding Logits, Sigmoid, Softmax, and Cross-Entropy Loss in Deep Learning},
  howpublished = {Available at: \url{https://wandb.ai/amanarora/Written-Reports/reports/Understanding-Logits-Sigmoid-Softmax-and-Cross-Entropy-Loss-in-Deep-Learning--Vmlldzo0NDMzNTU3}},
  note         = {Accessed: 31-12-2024, 2022}
}

% Optimization Ablation Study
@misc{he2018bagtricksimageclassification,
      title={Bag of Tricks for Image Classification with Convolutional Neural Networks}, 
      author={Tong He and Zhi Zhang and Hang Zhang and Zhongyue Zhang and Junyuan Xie and Mu Li},
      year={2018},
      eprint={1812.01187},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1812.01187}, 
}

% Inductive Bias
@misc{kim2020inductivebias,
  author       = {medium.com},
  title        = {What is the Inductive Bias in Machine Learning?},
  howpublished = {Available at: \url{https://medium.com/@chkim345/what-is-the-inductive-bias-in-machine-learning-212a5f53e9aa}},
  note         = {Accessed: 31-12-2024, 2020}
}

7% Inductive Bias
@misc{cohen2017inductivebiasdeepconvolutional,
      title={Inductive Bias of Deep Convolutional Networks through Pooling Geometry}, 
      author={Nadav Cohen and Amnon Shashua},
      year={2017},
      eprint={1605.06743},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1605.06743}, 
}

% Margins - check
@article{Wang_2018,
   title={Additive Margin Softmax for Face Verification},
   volume={25},
   ISSN={1558-2361},
   url={http://dx.doi.org/10.1109/LSP.2018.2822810},
   DOI={10.1109/lsp.2018.2822810},
   number={7},
   journal={IEEE Signal Processing Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Wang, Feng and Cheng, Jian and Liu, Weiyang and Liu, Haijun},
   year={2018},
   month=jul, pages={926–930} 
}

% ImageNet ILSVRC - check
@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

% Metrics
@article{metrics,
    author = {Opitz, Juri},
    title = {A Closer Look at Classification Evaluation Metrics and a Critical
                    Reflection of Common Evaluation Practice},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {12},
    pages = {820-836},
    year = {2024},
    month = {06},
    doi = {10.1162/tacl_a_00675},
}

% Related work, margin - check
@misc{liu2017largemarginsoftmaxlossconvolutional,
      title={Large-Margin Softmax Loss for Convolutional Neural Networks}, 
      author={Weiyang Liu and Yandong Wen and Zhiding Yu and Meng Yang},
      year={2017},
      eprint={1612.02295},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1612.02295}, 
}
% ===============================================================================
% Loss Functions

% Cross-Entropy Loss - check
@misc{pytorch_crossentropy,
  title = {CrossEntropyLoss},
  author = {pytorch.org},
  year = {2024},
  howpublished = {Available at: \url{https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html}},
  note         = {Accessed: 20-11-2024}
}

% Cross-Entropy Loss
@misc{mao2023crossentropylossfunctionstheoretical,
      title={Cross-Entropy Loss Functions: Theoretical Analysis and Applications}, 
      author={Anqi Mao and Mehryar Mohri and Yutao Zhong},
      year={2023},
      eprint={2304.07288},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2304.07288}, 
}

% Focal Loss - check
@misc{lin2018focallossdenseobject,
      title={Focal Loss for Dense Object Detection}, 
      author={Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
      year={2018},
      eprint={1708.02002},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1708.02002}, 
}

% Class-Balanced Loss - check
@misc{cui2019classbalancedlossbasedeffective,
      title={Class-Balanced Loss Based on Effective Number of Samples}, 
      author={Yin Cui and Menglin Jia and Tsung-Yi Lin and Yang Song and Serge Belongie},
      year={2019},
      eprint={1901.05555},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1901.05555}, 
}

% Balanced Softmax Loss - check
@misc{ren2020balancedmetasoftmaxlongtailedvisual,
      title={Balanced Meta-Softmax for Long-Tailed Visual Recognition}, 
      author={Jiawei Ren and Cunjun Yu and Shunan Sheng and Xiao Ma and Haiyu Zhao and Shuai Yi and Hongsheng Li},
      year={2020},
      eprint={2007.10740},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.10740}, 
}

% LDAM-DRW - check
@misc{cao2019learningimbalanceddatasetslabeldistributionaware,
      title={Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss}, 
      author={Kaidi Cao and Colin Wei and Adrien Gaidon and Nikos Arechiga and Tengyu Ma},
      year={2019},
      eprint={1906.07413},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1906.07413}, 
}

% Equalization Loss - check
@misc{tan2020equalizationlosslongtailedobject,
      title={Equalization Loss for Long-Tailed Object Recognition}, 
      author={Jingru Tan and Changbao Wang and Buyu Li and Quanquan Li and Wanli Ouyang and Changqing Yin and Junjie Yan},
      year={2020},
      eprint={2003.05176},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2003.05176}, 
}


% ===============================================================================
% Datasets

% CIFAR-100 - check
@techreport{krizhevsky2009learning,
  author = {Krizhevsky, Alex and Hinton, Geoffrey},
  title = {Learning Multiple Layers of Features from Tiny Images},
  institution = {University of Toronto},
  year = {2009},
  type = {Technical Report},
}


@misc{pytorch_cifar100,
  title = {CIFAR100},
  author = {pytorch.org},
  year = {2024},
  howpublished = {Available at: \url{https://pytorch.org/vision/0.17/generated/torchvision.datasets.CIFAR100.html}},
  note         = {Accessed: 13-12-2024}
}

% Dataset Distribution - check
@misc{liu2019largescalelongtailedrecognitionopen,
      title={Large-Scale Long-Tailed Recognition in an Open World}, 
      author={Ziwei Liu and Zhongqi Miao and Xiaohang Zhan and Jiayun Wang and Boqing Gong and Stella X. Yu},
      year={2019},
      eprint={1904.05160},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1904.05160}, 
}

% Dataset Distribution - check
@article{Newman_2005,
   title={Power laws, Pareto distributions and Zipf’s law},
   volume={46},
   ISSN={1366-5812},
   url={http://dx.doi.org/10.1080/00107510500052444},
   DOI={10.1080/00107510500052444},
   number={5},
   journal={Contemporary Physics},
   publisher={Informa UK Limited},
   author={Newman, MEJ},
   year={2005},
   month=sep, pages={323–351} }

% Class imbalance -check
@article{Buda_2018,
   title={A systematic study of the class imbalance problem in convolutional neural networks},
   volume={106},
   ISSN={0893-6080},
   url={http://dx.doi.org/10.1016/j.neunet.2018.07.011},
   DOI={10.1016/j.neunet.2018.07.011},
   journal={Neural Networks},
   publisher={Elsevier BV},
   author={Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A.},
   year={2018},
   month=oct, pages={249–259} }

% Imbalanced Datasets - check
@misc{vanhorn2017deviltailsfinegrainedclassification,
      title={The Devil is in the Tails: Fine-grained Classification in the Wild}, 
      author={Grant Van Horn and Pietro Perona},
      year={2017},
      eprint={1709.01450},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1709.01450}, 
}

% iNaturalist - check
@misc{vanhorn2018inaturalistspeciesclassificationdetection,
      title={The iNaturalist Species Classification and Detection Dataset}, 
      author={Grant Van Horn and Oisin Mac Aodha and Yang Song and Yin Cui and Chen Sun and Alex Shepard and Hartwig Adam and Pietro Perona and Serge Belongie},
      year={2018},
      eprint={1707.06642},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1707.06642}, 
}

% Long-tailed illustration
@misc{lgresearch257,
  author       = {lgresearch.ai},
  title        = {[ICML 2022] Part 1: Long-Tail Distribution Learning},
  howpublished = {Available at: \url{https://www.lgresearch.ai/blog/view/?seq=257&page=1&pageSize=12}},
  note         = {Accessed: 26-11-2024, 2022}
}

% ImageNet - check
@INPROCEEDINGS{ImageNet2009,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}
}

% Places365
@inproceedings{Places365,
 author = {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning Deep Features for Scene Recognition using Places Database},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/3fe94a002317b5f9259f82690aeea4cd-Paper.pdf},
 volume = {27},
 year = {2014}
}

% Distribution, survey - check
@misc{dealvis2024surveydeeplongtailclassification,
      title={A Survey of Deep Long-Tail Classification Advancements}, 
      author={Charika de Alvis and Suranga Seneviratne},
      year={2024},
      eprint={2404.15593},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.15593}, 
}

% ===============================================================================
% MLP
Check
@article{HORNIK1989359,
title = {Multilayer feedforward networks are universal approximators},
journal = {Neural Networks},
volume = {2},
number = {5},
pages = {359-366},
year = {1989},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
}

% ===============================================================================
% Model architechture references

% MobileNetV1 - check
@misc{howard2017mobilenetsefficientconvolutionalneural,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}, 
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1704.04861}, 
}

% MobileNetV2 - check
@misc{sandler2018mobilenetv2,
      title={MobileNetV2: Inverted Residuals and Linear Bottlenecks}, 
      author={Mark Sandler and Andrew Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
      year={2019},
      eprint={1801.04381},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1801.04381}, 
}

% MobileNetV2 PyTorch
@manual{pytorch_mobilenetv2,
  title        = {MobileNetV2},
  author       = {pytorch.org},
  year         = {2024},
  url          = {https://pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v2.html#torchvision.models.mobilenet_v2},
  note         = {Accessed: 22-12-2024}
}




% MobileNetV2 article
@misc{analyticsvidhya2023mobilenetv2,
  author       = {{Analytics Vidhya}},
  title        = {What is MobileNetv2?},
  year         = {2023},
  howpublished = {\url{https://www.analyticsvidhya.com/blog/2023/12/what-is-mobilenetv2/}},
  note         = {Accessed: 2024-12-24}
}

% MobileNetV2 Use
@INPROCEEDINGS{10127955,
  author={Varur, Sneha and Mainale, Sangamesh and Korishetty, Sushmita and Shanbhag, Akshay and Kulkarni, Uday and M, Meena S.},
  booktitle={2023 3rd International Conference on Smart Data Intelligence (ICSMDI)}, 
  title={Classification of Maturity Stages of Coconuts using Deep Learning on Embedded Platforms}, 
  year={2023},
  volume={},
  number={},
  pages={343-349},
  doi={10.1109/ICSMDI57622.2023.00067}
}

check
@article{shahi2022fruit,
  title={Fruit classification using attention-based MobileNetV2 for industrial applications},
  author={Shahi, Tika B and Sitaula, Chandra and Neupane, Anish and Guo, Wei},
  journal={PLOS ONE},
  volume={17},
  number={2},
  pages={e0264586},
  year={2022},
  publisher={Public Library of Science},
  doi={10.1371/journal.pone.0264586}
}

% Resize
@misc{talebi2021learningresizeimagescomputer,
      title={Learning to Resize Images for Computer Vision Tasks}, 
      author={Hossein Talebi and Peyman Milanfar},
      year={2021},
      eprint={2103.09950},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.09950}, 
}

% Study of pretrained models
@article{asiri2023advancing,
  title={Advancing Brain Tumor Classification through Fine-Tuned Vision Transformers: A Comparative Study of Pre-Trained Models},
  author={Asiri, A. A. and Shaf, A. and Ali, T. and Pasha, M. A. and Aamir, M. and Irfan, M. and Alqahtani, S. and Alghamdi, A. J. and Alghamdi, A. H. and Alshamrani, A. F. A. and Alelyani, M. and Alamri, S.},
  journal={Sensors (Basel, Switzerland)},
  volume={23},
  number={18},
  pages={7913},
  year={2023},
  doi={10.3390/s23187913}
}


% MobileNetV2 Use + Transfer Learning - check
@misc{surya2024enhancedbreastcancertumor,
      title={Enhanced Breast Cancer Tumor Classification using MobileNetV2: A Detailed Exploration on Image Intensity, Error Mitigation, and Streamlit-driven Real-time Deployment}, 
      author={Aaditya Surya and Aditya Shah and Jarnell Kabore and Subash Sasikumar},
      year={2024},
      eprint={2312.03020},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2312.03020}, 
}

% ViT-B/16 - check
@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

% ViT-B/16 - check
@misc{torchvision2024vitb16,
  title = {Vision Transformer (ViT-B-16)},
  author = {pytorch.org},
  year = {2024},
  howpublished = {Available at: \url{https://pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html}},
  note = {Accessed: 04-12-2024}
}

% ViT-B/16
@misc{huggingface2024vitbase,
  author       = {huggingface.co},
  title        = {ViT Base Patch16-224 by Google},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/google/vit-base-patch16-224}},
  note         = {Accessed: 04-12-2024}
}

% ViT optimization
@misc{beyer2022betterplainvitbaselines,
      title={Better plain ViT baselines for ImageNet-1k}, 
      author={Lucas Beyer and Xiaohua Zhai and Alexander Kolesnikov},
      year={2022},
      eprint={2205.01580},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2205.01580}, 
}

% PyToch Implementation
@misc{torchvision-vit,
  title = {Vision Transformer Implementation in TorchVision},
  author = {TorchVision Contributors},
  year = {2023},
  howpublished = {\url{https://github.com/pytorch/vision/blob/main/torchvision/models/vision_transformer.py}},
  note = {Accessed: 2024-12-18}
}


% ResNet50V2 proposed here - check
@misc{he2016identitymappingsdeepresidual,
      title={Identity Mappings in Deep Residual Networks}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2016},
      eprint={1603.05027},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1603.05027}, 
}

check
@misc{wightman2021resnetstrikesbackimproved,
      title={ResNet strikes back: An improved training procedure in timm}, 
      author={Ross Wightman and Hugo Touvron and Hervé Jégou},
      year={2021},
      eprint={2110.00476},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2110.00476}, 
}

% ResNet - check
@misc{he2015deepresiduallearningimage,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}
}

% ResNet50 PyTorch: - check
@misc{torchvision-resnet,
    author = {TorchVision maintainers and contributors},
    title = {TorchVision: PyTorch's Computer Vision library},
    year = {2016},
    howpublished = {Available at: \url{https://github.com/pytorch/vision}},
    note = {Accessed: 18-12-2024}
}

@misc{pytorchresnet,
    author = {pytorch.org},
    title = {resnet50},
    year = {2024},
    howpublished = {Available at: \url{https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html}},
    note = {Accessed: 26-11-2024}
}


@misc{pytorch-convnext,
    author = {pytorch.org},
    title = {convnext base},
    year = {2024},
    howpublished = {Available at: \url{https://pytorch.org/vision/main/models/generated/torchvision.models.convnext_base.html}},
    note = {Accessed: 26-11-2024}
}




% ResNet article
@misc{towardsdatascience_resnet,
  author       = {Sumit Saha},
  title        = {Review: ResNet — Winner of ILSVRC 2015 (Image Classification, Localization, Detection)},
  year         = {2018},
  url          = {https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8},
  note         = {Accessed: 2024-12-22}
}

% ResNet Transfer Learning
@article{RAZAVI2024123276,
title = {ResNet deep models and transfer learning technique for classification and quality detection of rice cultivars},
journal = {Expert Systems with Applications},
volume = {247},
pages = {123276},
year = {2024},
doi = {https://doi.org/10.1016/j.eswa.2024.123276},
author = {Mohammad Razavi and Samira Mavaddati and Hamidreza Koohi},
}

% ResNet Transfer Learning
@InProceedings{resnettransfer,
author="Liu, Le
and Cheng, Jieren
and Xie, Luyi
and Song, Jinyang
and Zhou, Ke
and Liu, Jingxin",
title="A Transfer Learning Method Based on ResNet Model",
booktitle="Data Mining and Big Data",
year="2021",
publisher="Springer Singapore",
pages="250--260",
}

% Resnet Transfer Learning


@misc{chan2019transfer,
  author       = {medium.com},
  title        = {A Guide to Transfer Learning with Keras Using ResNet50},
  howpublished = {Available at: \url{https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b}},
  note         = {Accessed: 23-12-2024, 2019}
}

% Resnet Transfer Learning
@misc{sinha2024transferlearning,
  author       = {Ritesh Sinha},
  title        = {Transfer Learning Using ResNet},
  year         = {2024},
  howpublished = {\url{https://www.kaggle.com/code/riteshsinha/transfer-learning-using-resnet}},
  note         = {Accessed: 2024-12-24}
}


% ResNet layers - check
@INPROCEEDINGS{10083966,
  author={Nagpal, Piyush and Bhinge, Shivani Atul and Shitole, Ajitkumar},
  booktitle={2022 International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)}, 
  title={A Comparative Analysis of ResNet Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/SMARTGENCON56628.2022.10083966}}

% ResNet Overview Blog
@misc{innovatiana_resnet50,
  author = {Innovatiana},
  title = {Discover ResNet-50},
  year = {2023},
  url = {https://en.innovatiana.com/post/discover-resnet-50},
  note = {Accessed: 2024-12-23}
}


% ResNet Usage
@Article{Shafiq2022,
AUTHOR = {Shafiq, Muhammad and Gu, Zhaoquan},
TITLE = {Deep Residual Learning for Image Recognition: A Survey},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {18},
ARTICLE-NUMBER = {8972},
DOI = {10.3390/app12188972}
}

% ResNet Medical Imaging - check
@misc{huang2022identifyingkeycomponentsresnet50,
      title={Identifying the key components in ResNet-50 for diabetic retinopathy grading from fundus images: a systematic investigation}, 
      author={Yijin Huang and Li Lin and Pujin Cheng and Junyan Lyu and Roger Tam and Xiaoying Tang},
      year={2022},
      eprint={2110.14160},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2110.14160}, 
}

check
@InProceedings{Simegn,
author="Simegn, Gizeaddis Lamesgin
and Degu, Mizanu Zelalem
and Tegenaw, Geletaw Sahle",
title="Cervical Cancer Histopathological Image Classification Using Imbalanced Domain Learning",
booktitle="Advancement of Science and Technology",
year="2025",
publisher="Springer Nature Switzerland",
pages="3--20",
}

% ResNet-50 Flower Detection
@inproceedings{resnet_flower,
author = {Jaju, Sanay and Chandak, Manoj},
year = {2022},
month = {05},
pages = {307-311},
title = {A Transfer Learning Model Based on ResNet-50 for Flower Detection},
doi = {10.1109/ICAAIC53929.2022.9792697}
}

% Pest Detection - check
@INPROCEEDINGS{10112802,
  author={S, Umamaheswari and R, Vishal N and R, Pragadesh N and S, Lavanya},
  booktitle={2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={Performance Analysis of ResNet50 Architecture based Pest Detection System}, 
  year={2023},
  volume={1},
  number={},
  pages={578-583},
  doi={10.1109/ICACCS57279.2023.10112802}
}

% Face Detection - check
@INPROCEEDINGS{Nyarko2022,
  author={Esi Nyarko, Benedicta Nana and Bin, Wu and Zhou, Jinzhi and Agordzo, George K. and Odoom, Justice and Koukoyi, Ebenezer},
  booktitle={2022 IEEE World AI IoT Congress (AIIoT)}, 
  title={Comparative Analysis of AlexNet, Resnet-50, and Inception-V3 Models on Masked Face Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={337-343},
  doi={10.1109/AIIoT54504.2022.9817327}}


% ConvNeXt - check
@article{todi2023convnext,
  title={ConvNext: A Contemporary Architecture for Convolutional Neural Networks for Image Classification},
  author={Agastya Todi and Navya Narula and Moolchand Sharma and Umesh Gupta},
  journal={2023 3rd International Conference on Innovative Sustainable Computational Technologies (CISCT)},
  year={2023},
  pages={1-6},
  url={https://api.semanticscholar.org/CorpusID:266486570}
}



% ConvNet - check
@misc{liu2022convnet2020s,
      title={A ConvNet for the 2020s}, 
      author={Zhuang Liu and Hanzi Mao and Chao-Yuan Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie},
      year={2022},
      eprint={2201.03545},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.03545}, 
}

% ConvNeXt Base


@misc{torchvision2024convnextbase,
  title = {convnextbase},
  author = {pytorch.org},
  year = {2024},
  howpublished = {Available at: \url{https://pytorch.org/vision/main/models/generated/torchvision.models.convnext_base.html}},
  note = {Accessed: 04-12-2024}
}

% ConvNext Implementation
@misc{torchvision-convnext,
  title = {ConvNeXt Implementation in TorchVision},
  author = {TorchVision Contributors},
  year = {2023},
  howpublished = {\url{https://github.com/pytorch/vision/blob/main/torchvision/models/convnext.py}},
  note = {Accessed: 2024-12-18}
}

% ResNeXt - check
@misc{xie2017aggregatedresidualtransformationsdeep,
      title={Aggregated Residual Transformations for Deep Neural Networks}, 
      author={Saining Xie and Ross Girshick and Piotr Dollár and Zhuowen Tu and Kaiming He},
      year={2017},
      eprint={1611.05431},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1611.05431}, 
}

% EfficientNet
@misc{tan2020efficientnetrethinkingmodelscaling,
      title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}, 
      author={Mingxing Tan and Quoc V. Le},
      year={2020},
      eprint={1905.11946},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1905.11946}, 
}

% Transfer Learning on large datasets
@misc{kolesnikov2020bigtransferbitgeneral,
      title={Big Transfer (BiT): General Visual Representation Learning}, 
      author={Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Joan Puigcerver and Jessica Yung and Sylvain Gelly and Neil Houlsby},
      year={2020},
      eprint={1912.11370},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1912.11370}, 
}

% Fine-tuning - check
@misc{ye2023partialfinetuningsuccessorfinetuning,
      title={Partial Fine-Tuning: A Successor to Full Fine-Tuning for Vision Transformers}, 
      author={Peng Ye and Yongqi Huang and Chongjun Tu and Minglei Li and Tao Chen and Tong He and Wanli Ouyang},
      year={2023},
      eprint={2312.15681},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.15681}, 
}

% Transfer Learning
@Article{kandel2020,
AUTHOR = {Kandel, Ibrahem and Castelli, Mauro},
TITLE = {How Deeply to Fine-Tune a Convolutional Neural Network: A Case Study Using a Histopathology Dataset},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {3359},
DOI = {10.3390/app10103359}
}

% Transfer Learning - check
@misc{yosinski2014transferablefeaturesdeepneural,
      title={How transferable are features in deep neural networks?}, 
      author={Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
      year={2014},
      eprint={1411.1792},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1411.1792}, 
}
% ===============================================================================
% Convolutional Neural Network references

Check
@ARTICLE{lecun1995,
author = {LeCun, Yann and Jackel, Larry and Bottou, L. and Brunot, A. and Cortes, Corinna and Denker, John and Drucker, Harris and Guyon, Isabelle and Muller, Urs and Sackinger, E. and Simard, Patrice and Vapnik, V.},
journal = {International Conference on Artificial Neural Networks},
year = {1995},
month = {01},
pages = {},
title = {Comparison of learning algorithms for handwritten digit recognition},
}


Check
@ARTICLE{lecun1998,
  author={LeCun, Yann and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  journal={Neural Computation}, 
  title={Backpropagation Applied to Handwritten Zip Code Recognition}, 
  year={1989},
  volume={1},
  number={4},
  pages={541-551},
  keywords={},
  doi={10.1162/neco.1989.1.4.541}}


% Figure
@misc{ibm_cnn,
  author = {ibm.com},
  title        = {What are cconvolutional neural networks?},
  howpublished = {Available: \url{https://www.ibm.com/think/topics/convolutional-neural-networks}},
  note         = {Accessed: 26-12-2024, 2024}
}

@misc{medium_resnet,
  author = {medium.com},
  title        = {The Annotated ResNet-50},
  howpublished = {Available: \url{https://towardsdatascience.com/the-annotated-resnet-50-a6c536034758}},
  note         = {Accessed: 03-01-20245, 2022}
}


@misc{mathworks_cnn,
  author = {mathworks.com},
  title        = {What Is a Convolutional Neural Network?},
  howpublished = {Available: \url{https://www.mathworks.com/discovery/convolutional-neural-network.html}},
  note         = {Accessed: 28-11-2024, 2024}
}

% ConvNext guide
@misc{convnext_guide,
  author = {kungfu.ai},
  title        = {ConvNeXt: A Transformer-Inspired CNN Architecture},
  howpublished = {Available: \url{https://www.kungfu.ai/blog-post/convnext-a-transformer-inspired-cnn-architecture}},
  note         = {Accessed: 28-11-2024, 2023}
}

% AlexNet - check
@ARTICLE{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 journal = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 volume = {25},
 note = {Available at: \url{https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf}},
 year = {2012}
}

% VGGNet - check
@misc{simonyan2015deepconvolutionalnetworkslargescale,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

% GoogLeNet - check
@misc{szegedy2014goingdeeperconvolutions,
      title={Going Deeper with Convolutions}, 
      author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
      year={2014},
      eprint={1409.4842},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.4842}, 
}

% Depthwise Seperable Convolution
@misc{guo2019depthwiseconvolutionneedlearning,
      title={Depthwise Convolution is All You Need for Learning Multiple Visual Domains}, 
      author={Yunhui Guo and Yandong Li and Rogerio Feris and Liqiang Wang and Tajana Rosing},
      year={2019},
      eprint={1902.00927},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1902.00927}, 
}

% GeLu
@misc{hendrycks2023gaussianerrorlinearunits,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2023},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1606.08415}, 
}

% ReLU
@inproceedings{relu,
author = {Nair, Vinod and Hinton, Geoffrey E.},
title = {Rectified linear units improve restricted boltzmann machines},
year = {2010},
publisher = {Omnipress},
booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
pages = {807–814},
numpages = {8},
series = {ICML'10}
}
% ===============================================================================
% Vision Transformer references

@misc{raghu2022visiontransformerslikeconvolutional,
      title={Do Vision Transformers See Like Convolutional Neural Networks?}, 
      author={Maithra Raghu and Thomas Unterthiner and Simon Kornblith and Chiyuan Zhang and Alexey Dosovitskiy},
      year={2022},
      eprint={2108.08810},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2108.08810}, 
}

% Transformer - check
@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

% Guide
@misc{v7labs-vit,
  title = {Vision Transformer Guide},
  author = {v7labs.com},
  year = {2024},
  howpublished = {\url{https://www.v7labs.com/blog/vision-transformer-guide}},
  note = {Accessed: 18-12-2024}
}


% ===============================================================================
% GitHub Repositories

% Deep Long-Tailed Learning: A Survey
@misc{VanintLT,
  author = {Vanint},
  title = {Awesome-LongTailed-Learning},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Vanint/Awesome-LongTailed-Learning}},
  commit = {2269dfe0e2bf4d6d4b88eb414614ecd1738bfc67},
  note = {Accessed: 2024-09-18}
}

% LDAM-DRW
@misc{kaidic_ldam_drw,
  author       = {Kai, Di},
  title        = {LDAM-DRW: Learning from Long-Tailed Data},
  howpublished = {GitHub repository, [Online]},
  note         = {Available: \url{https://github.com/kaidic/LDAM-DRW/tree/master}. Accessed: 2024-09-18},
}




% ===============================================================================
% Optimizers

@misc{choi2020empiricalcomparisonsoptimizersdeep,
      title={On Empirical Comparisons of Optimizers for Deep Learning}, 
      author={Dami Choi and Christopher J. Shallue and Zachary Nado and Jaehoon Lee and Chris J. Maddison and George E. Dahl},
      year={2020},
      eprint={1910.05446},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.05446}, 
}

% StepLR - check
@misc{pytorch_steplr,
  author = {pytorch.org},
  howpublished = {Available at: \url{https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html}},
  title = {StepLR},
  year = {2024},
  note = {Accessed: 04-12-2024}
}

% Adam optimizer weight decay - check
@misc{loshchilov2018fixing,
title={Fixing Weight Decay Regularization in Adam},
author={Ilya Loshchilov and Frank Hutter},
year={2018},
url={https://openreview.net/forum?id=rk6qdGgCZ},
}

Adam - check
@misc{kingma2017adammethodstochasticoptimization,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}


check
@misc{pytorch_adam,
  author = {pytorch.org},
  howpublished = {Available at: \url{https://pytorch.org/docs/stable/generated/torch.optim.Adam.html}},
  title = {Adam},
  year = {2024},
  note = {Accessed: 04-12-2024}
}

% Implicit bias - check
@misc{soudry2024implicitbias,
      title={The Implicit Bias of Gradient Descent on Separable Data}, 
      author={Daniel Soudry and Elad Hoffer and Mor Shpigel Nacson and Suriya Gunasekar and Nathan Srebro},
      year={2024},
      eprint={1710.10345},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1710.10345}, 
}


% SGD
@book{cauchy1829,
  author    = {A. L. Cauchy},
  title     = {Leçons sur le calcul différentiel},
  year      = {1829},
  publisher = {Paris},
}

% ===============================================================================
% Benchmarks

% Mobilenetv2
@misc{wang2019e2traintrainingstateoftheartcnns,
      title={E2-Train: Training State-of-the-art CNNs with Over 80% Energy Savings}, 
      author={Yue Wang and Ziyu Jiang and Xiaohan Chen and Pengfei Xu and Yang Zhao and Yingyan Lin and Zhangyang Wang},
      year={2019},
      eprint={1910.13349},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.13349}, 
}

check
@misc{park2022bitatneuralnetworkbinarization,
      title={BiTAT: Neural Network Binarization with Task-dependent Aggregated Transformation}, 
      author={Geon Park and Jaehong Yoon and Haiyang Zhang and Xing Zhang and Sung Ju Hwang and Yonina C. Eldar},
      year={2022},
      eprint={2207.01394},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2207.01394}, 
}


% ViT-B/16
@inproceedings{Tseng_2022,
   title={Perturbed Gradients Updating within Unit Space for Deep Learning},
   url={http://dx.doi.org/10.1109/IJCNN55064.2022.9892245},
   DOI={10.1109/ijcnn55064.2022.9892245},
   booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
   publisher={IEEE},
   author={Tseng, Ching-Hsun and Liu, Hsueh-Cheng and Lee, Shin-Jye and Zeng, Xiaojun},
   year={2022},
   month=jul, pages={01-08} }

% Conv2NeXt
@INPROCEEDINGS{10072172,
  author={Feng, Jianwei and Tan, Hengliang and Li, Wangwang and Xie, Ming},
  booktitle={2022 International Conference on Computers and Artificial Intelligence Technologies (CAIT)}, 
  title={Conv2NeXt: Reconsidering Conv NeXt Network Design for Image Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={53-60},
  doi={10.1109/CAIT56099.2022.10072172}}


% ===============================================================================
% Related Work

% Re-sampling, SMOTE - check
@article{Chawla_2002,
   title={SMOTE: Synthetic Minority Over-sampling Technique},
   volume={16},
   ISSN={1076-9757},
   url={http://dx.doi.org/10.1613/jair.953},
   DOI={10.1613/jair.953},
   journal={Journal of Artificial Intelligence Research},
   publisher={AI Access Foundation},
   author={Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
   year={2002},
   month=jun, 
   pages={321-357} 
}

% Not used
@inproceedings{han2005,
      author = {Han, Hui and Wang, Wen-Yuan and Mao, Bing-Huan},
      title = {Borderline-SMOTE: a new over-sampling method in imbalanced data sets learning},
      year = {2005},
      isbn = {3540282262},
      publisher = {Springer-Verlag},
      address = {Berlin, Heidelberg},
      url = {https://doi.org/10.1007/11538059_91},
      doi = {10.1007/11538059_91},
      booktitle = {Proceedings of the 2005 International Conference on Advances in Intelligent Computing - Volume Part I},
      pages = {878–887},
      numpages = {10},
      location = {Hefei, China},
      series = {ICIC'05}
}

% Few-Shot Learning
@misc{wang2020generalizingexamplessurveyfewshot,
      title={Generalizing from a Few Examples: A Survey on Few-Shot Learning}, 
      author={Yaqing Wang and Quanming Yao and James Kwok and Lionel M. Ni},
      year={2020},
      eprint={1904.05046},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1904.05046}, 
}

% Logit Adjustment - check
@misc{menon2021longtaillearninglogitadjustment,
      title={Long-tail learning via logit adjustment}, 
      author={Aditya Krishna Menon and Sadeep Jayasumana and Ankit Singh Rawat and Himanshu Jain and Andreas Veit and Sanjiv Kumar},
      year={2021},
      eprint={2007.07314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.07314}, 
}

% Survey
@misc{zhang2024systematicreviewlongtailedlearning,
      title={A Systematic Review on Long-Tailed Learning}, 
      author={Chongsheng Zhang and George Almpanidis and Gaojuan Fan and Binquan Deng and Yanbo Zhang and Ji Liu and Aouaidjia Kamel and Paolo Soda and João Gama},
      year={2024},
      eprint={2408.00483},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.00483}, 
}

% Data Augmentation - check
@misc{perez2017effectivenessdataaugmentationimage,
      title={The Effectiveness of Data Augmentation in Image Classification using Deep Learning}, 
      author={Luis Perez and Jason Wang},
      year={2017},
      eprint={1712.04621},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1712.04621}, 
}

% Data Augmentation - check
@article{shorten2019survey,
    author = {Connor Shorten and Taghi M. Khoshgoftaar},
    title = {A survey on Image Data Augmentation for Deep Learning},
    journal = {Journal of Big Data},
    year = {2019},
    volume = {6},
    number = {1},
    pages = {60},
    doi = {10.1186/s40537-019-0197-0},
    url = {https://doi.org/10.1186/s40537-019-0197-0},
}


% CutMix - check
@misc{yun2019cutmixregularizationstrategytrain,
      title={CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features}, 
      author={Sangdoo Yun and Dongyoon Han and Seong Joon Oh and Sanghyuk Chun and Junsuk Choe and Youngjoon Yoo},
      year={2019},
      eprint={1905.04899},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1905.04899}, 
}

% MixUp - check
@misc{zhang2018mixupempiricalriskminimization,
      title={mixup: Beyond Empirical Risk Minimization}, 
      author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
      year={2018},
      eprint={1710.09412},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1710.09412}, 
}

% RandAugment - check
@misc{cubuk2019randaugmentpracticalautomateddata,
      title={RandAugment: Practical automated data augmentation with a reduced search space}, 
      author={Ekin D. Cubuk and Barret Zoph and Jonathon Shlens and Quoc V. Le},
      year={2019},
      eprint={1909.13719},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1909.13719}, 
}

% UniMix - check
@misc{xu2021calibratedmodellongtailedvisual,
      title={Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective}, 
      author={Zhengzhuo Xu and Zenghao Chai and Chun Yuan},
      year={2021},
      eprint={2111.03874},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2111.03874}, 
}

% MiSLAS
@misc{zhong2021improvingcalibrationlongtailedrecognition,
      title={Improving Calibration for Long-Tailed Recognition}, 
      author={Zhisheng Zhong and Jiequan Cui and Shu Liu and Jiaya Jia},
      year={2021},
      eprint={2104.00466},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2104.00466}, 
}

% RSG - check
@misc{wang2021rsgsimpleeffectivemodule,
      title={RSG: A Simple but Effective Module for Learning Imbalanced Datasets}, 
      author={Jianfeng Wang and Thomas Lukasiewicz and Xiaolin Hu and Jianfei Cai and Zhenghua Xu},
      year={2021},
      eprint={2106.09859},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2106.09859}, 
}

% Decoupling
@misc{kang2020decouplingrepresentationclassifierlongtailed,
      title={Decoupling Representation and Classifier for Long-Tailed Recognition}, 
      author={Bingyi Kang and Saining Xie and Marcus Rohrbach and Zhicheng Yan and Albert Gordo and Jiashi Feng and Yannis Kalantidis},
      year={2020},
      eprint={1910.09217},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1910.09217}, 
}

% Transfer Learning - check
@misc{yin2019featuretransferlearningdeep,
      title={Feature Transfer Learning for Deep Face Recognition with Under-Represented Data}, 
      author={Xi Yin and Xiang Yu and Kihyuk Sohn and Xiaoming Liu and Manmohan Chandraker},
      year={2019},
      eprint={1803.09014},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1803.09014}, 
}

% Transfer Learning - check
@ARTICLE{pan2010,
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Transfer Learning}, 
  year={2010},
  volume={22},
  number={10},
  pages={1345-1359},
  doi={10.1109/TKDE.2009.191}
  }

% Transfer Learning
check
@article{Hinton2006,
author = {G. E. Hinton  and R. R. Salakhutdinov },
title = {Reducing the Dimensionality of Data with Neural Networks},
journal = {Science},
volume = {313},
number = {5786},
pages = {504-507},
year = {2006},
doi = {10.1126/science.1127647},
}

@inproceedings{Fu2021,
author = {Fu, Yang and Huang, Xiangnian and Li, Yunfeng},
title = {Horse Breed Classification Based on Transfer Learning},
year = {2021},
publisher = {Association for Computing Machinery},
doi = {10.1145/3441250.3441264},
booktitle = {Proceedings of the 4th International Conference on Advances in Image Processing},
pages = {42–47},
}


% Ensemble Learning - check
@misc{zhou2020bbnbilateralbranchnetworkcumulative,
      title={BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition}, 
      author={Boyan Zhou and Quan Cui and Xiu-Shen Wei and Zhao-Min Chen},
      year={2020},
      eprint={1912.02413},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1912.02413}, 
}

% Ensemble learning - check
@misc{wang2022longtailedrecognitionroutingdiverse,
      title={Long-tailed Recognition by Routing Diverse Distribution-Aware Experts}, 
      author={Xudong Wang and Long Lian and Zhongqi Miao and Ziwei Liu and Stella X. Yu},
      year={2022},
      eprint={2010.01809},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.01809}, 
}
%=================================================================================
% PyTorch

@misc{paszke2019pytorchimperativestylehighperformance,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.01703}, 
}