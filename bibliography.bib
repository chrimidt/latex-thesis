% Main article: Deep Long-Tailed Learning: A Survey
@article{zhang2023deep,
      title={Deep long-tailed learning: A survey},
      author={Zhang, Yifan and Kang, Bingyi and Hooi, Bryan and Yan, Shuicheng and Feng, Jiashi},
      journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
      year={2023},
      publisher={IEEE}
}

% Background Theory
@book{zhang2023dive,
    title={Dive into Deep Learning},
    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
    publisher={Cambridge University Press},
    note={\url{https://D2L.ai}},
    year={2023}
}

% Background Theory
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{cs231n,
    author       = {X. L. Chaitanya Asawa},
    title        = {CS231n: Convolutional Neural Networks for Visual Recognition},
    note         = {Stanford, [Online]},
    howpublished = {\url{http://cs231n.github.io/}},
    year         = {2024}
}


% Gradients
@ARTICLE{279181,
  author={Bengio, Y. and Simard, P. and Frasconi, P.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Learning long-term dependencies with gradient descent is difficult}, 
  year={1994},
  volume={5},
  number={2},
  pages={157-166},
  doi={10.1109/72.279181}
}

% Optimization Ablation Study
@misc{he2018bagtricksimageclassification,
      title={Bag of Tricks for Image Classification with Convolutional Neural Networks}, 
      author={Tong He and Zhi Zhang and Hang Zhang and Zhongyue Zhang and Junyuan Xie and Mu Li},
      year={2018},
      eprint={1812.01187},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1812.01187}, 
}

% Inductive Bias
@misc{kim2020inductivebias,
  author = {Kim, Christopher},
  title = {What is the Inductive Bias in Machine Learning?},
  year = {2020},
  howpublished = {\url{https://medium.com/@chkim345/what-is-the-inductive-bias-in-machine-learning-212a5f53e9aa}},
  note = {Accessed: 2024-12-18}
}

% Margins
@article{Wang_2018,
   title={Additive Margin Softmax for Face Verification},
   volume={25},
   ISSN={1558-2361},
   url={http://dx.doi.org/10.1109/LSP.2018.2822810},
   DOI={10.1109/lsp.2018.2822810},
   number={7},
   journal={IEEE Signal Processing Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Wang, Feng and Cheng, Jian and Liu, Weiyang and Liu, Haijun},
   year={2018},
   month=jul, pages={926–930} 
}

% ImageNet ILSVRC
@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

% Metrics
@article{metrics,
    author = {Opitz, Juri},
    title = {A Closer Look at Classification Evaluation Metrics and a Critical
                    Reflection of Common Evaluation Practice},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {12},
    pages = {820-836},
    year = {2024},
    month = {06},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00675},
    url = {https://doi.org/10.1162/tacl\_a\_00675},
}

% ===============================================================================
% Loss Functions

% Cross-Entropy Loss
@misc{pytorch_crossentropy,
    title        = {torch.nn.CrossEntropyLoss — PyTorch documentation},
    howpublished = {\url{https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html}},
    note         = {Accessed: 2024-11-20}
}

% Cross-Entropy Loss
@misc{mao2023crossentropylossfunctionstheoretical,
      title={Cross-Entropy Loss Functions: Theoretical Analysis and Applications}, 
      author={Anqi Mao and Mehryar Mohri and Yutao Zhong},
      year={2023},
      eprint={2304.07288},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2304.07288}, 
}

% Focal Loss
@misc{lin2018focallossdenseobject,
      title={Focal Loss for Dense Object Detection}, 
      author={Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
      year={2018},
      eprint={1708.02002},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1708.02002}, 
}

% Class-Balanced Loss
@misc{cui2019classbalancedlossbasedeffective,
      title={Class-Balanced Loss Based on Effective Number of Samples}, 
      author={Yin Cui and Menglin Jia and Tsung-Yi Lin and Yang Song and Serge Belongie},
      year={2019},
      eprint={1901.05555},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1901.05555}, 
}

% Balanced Softmax Loss
@misc{ren2020balancedmetasoftmaxlongtailedvisual,
      title={Balanced Meta-Softmax for Long-Tailed Visual Recognition}, 
      author={Jiawei Ren and Cunjun Yu and Shunan Sheng and Xiao Ma and Haiyu Zhao and Shuai Yi and Hongsheng Li},
      year={2020},
      eprint={2007.10740},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.10740}, 
}

% LDAM-DRW
@misc{cao2019learningimbalanceddatasetslabeldistributionaware,
      title={Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss}, 
      author={Kaidi Cao and Colin Wei and Adrien Gaidon and Nikos Arechiga and Tengyu Ma},
      year={2019},
      eprint={1906.07413},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1906.07413}, 
}

% Equalization Loss
@misc{tan2020equalizationlosslongtailedobject,
      title={Equalization Loss for Long-Tailed Object Recognition}, 
      author={Jingru Tan and Changbao Wang and Buyu Li and Quanquan Li and Wanli Ouyang and Changqing Yin and Junjie Yan},
      year={2020},
      eprint={2003.05176},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2003.05176}, 
}


% ===============================================================================
% Datasets

% CIFAR-100
@techreport{krizhevsky2009learning,
  author = {Krizhevsky, Alex and Hinton, Geoffrey},
  title = {Learning Multiple Layers of Features from Tiny Images},
  institution = {University of Toronto},
  year = {2009},
  type = {Technical Report},
}

@online{pytorch_cifar100,
  title        = {torchvision.datasets.CIFAR100},
  author       = {{PyTorch Contributors}},
  year         = {2024},
  url          = {https://pytorch.org/vision/0.17/generated/torchvision.datasets.CIFAR100.html},
  note         = {Accessed: 2024-12-13}
}

% Dataset Distribution
@misc{liu2019largescalelongtailedrecognitionopen,
      title={Large-Scale Long-Tailed Recognition in an Open World}, 
      author={Ziwei Liu and Zhongqi Miao and Xiaohang Zhan and Jiayun Wang and Boqing Gong and Stella X. Yu},
      year={2019},
      eprint={1904.05160},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1904.05160}, 
}

% Dataset Distribution
@article{Newman_2005,
   title={Power laws, Pareto distributions and Zipf’s law},
   volume={46},
   ISSN={1366-5812},
   url={http://dx.doi.org/10.1080/00107510500052444},
   DOI={10.1080/00107510500052444},
   number={5},
   journal={Contemporary Physics},
   publisher={Informa UK Limited},
   author={Newman, MEJ},
   year={2005},
   month=sep, pages={323–351} }

% Not used?
@article{Buda_2018,
   title={A systematic study of the class imbalance problem in convolutional neural networks},
   volume={106},
   ISSN={0893-6080},
   url={http://dx.doi.org/10.1016/j.neunet.2018.07.011},
   DOI={10.1016/j.neunet.2018.07.011},
   journal={Neural Networks},
   publisher={Elsevier BV},
   author={Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A.},
   year={2018},
   month=oct, pages={249–259} }

% Imbalanced Datasets
@misc{vanhorn2017deviltailsfinegrainedclassification,
      title={The Devil is in the Tails: Fine-grained Classification in the Wild}, 
      author={Grant Van Horn and Pietro Perona},
      year={2017},
      eprint={1709.01450},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1709.01450}, 
}

% iNaturalist
@misc{vanhorn2018inaturalistspeciesclassificationdetection,
      title={The iNaturalist Species Classification and Detection Dataset}, 
      author={Grant Van Horn and Oisin Mac Aodha and Yang Song and Yin Cui and Chen Sun and Alex Shepard and Hartwig Adam and Pietro Perona and Serge Belongie},
      year={2018},
      eprint={1707.06642},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1707.06642}, 
}

% Long-tailed illustration
@misc{lgresearch257,
  author       = {LG AI Research},
  title        = {[ICML 2022] Part 1: Long-Tail Distribution Learning},
  howpublished = {\url{https://www.lgresearch.ai/blog/view/?seq=257&page=1&pageSize=12}},
  note         = {Accessed: 2024-11-26}
}

% ImageNet
@INPROCEEDINGS{ImageNet2009,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

% Places365
@inproceedings{Places365,
 author = {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning Deep Features for Scene Recognition using Places Database},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/3fe94a002317b5f9259f82690aeea4cd-Paper.pdf},
 volume = {27},
 year = {2014}
}

% Distribution
@misc{dealvis2024surveydeeplongtailclassification,
      title={A Survey of Deep Long-Tail Classification Advancements}, 
      author={Charika de Alvis and Suranga Seneviratne},
      year={2024},
      eprint={2404.15593},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.15593}, 
}

% ===============================================================================
% MLP

@article{HORNIK1989359,
title = {Multilayer feedforward networks are universal approximators},
journal = {Neural Networks},
volume = {2},
number = {5},
pages = {359-366},
year = {1989},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
}

% ===============================================================================
% Model architechture references

% MobileNetV1
@misc{howard2017mobilenetsefficientconvolutionalneural,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}, 
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1704.04861}, 
}

% MobileNetV2
@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

% MobileNetV2 PyTorch
@manual{pytorch_mobilenetv2,
  title        = {MobileNetV2 — TorchVision 0.15.0 Documentation},
  author       = {PyTorch Team},
  year         = {2024},
  url          = {https://pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v2.html#torchvision.models.mobilenet_v2},
  note         = {Accessed: 2024-12-22}
}

% MobileNetV2 article
@misc{analyticsvidhya2023mobilenetv2,
  author       = {{Analytics Vidhya}},
  title        = {What is MobileNetv2?},
  year         = {2023},
  howpublished = {\url{https://www.analyticsvidhya.com/blog/2023/12/what-is-mobilenetv2/}},
  note         = {Accessed: 2024-12-24}
}

% MobileNetV2 Use
@INPROCEEDINGS{10127955,
  author={Varur, Sneha and Mainale, Sangamesh and Korishetty, Sushmita and Shanbhag, Akshay and Kulkarni, Uday and M, Meena S.},
  booktitle={2023 3rd International Conference on Smart Data Intelligence (ICSMDI)}, 
  title={Classification of Maturity Stages of Coconuts using Deep Learning on Embedded Platforms}, 
  year={2023},
  volume={},
  number={},
  pages={343-349},
  doi={10.1109/ICSMDI57622.2023.00067}
}

@article{shahi2022fruit,
  title={Fruit classification using attention-based MobileNetV2 for industrial applications},
  author={Shahi, Tika B and Sitaula, Chandra and Neupane, Anish and Guo, Wei},
  journal={PLOS ONE},
  volume={17},
  number={2},
  pages={e0264586},
  year={2022},
  publisher={Public Library of Science},
  doi={10.1371/journal.pone.0264586}
}

% Resize
@misc{talebi2021learningresizeimagescomputer,
      title={Learning to Resize Images for Computer Vision Tasks}, 
      author={Hossein Talebi and Peyman Milanfar},
      year={2021},
      eprint={2103.09950},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.09950}, 
}

% Study of pretrained models
@article{asiri2023advancing,
  title={Advancing Brain Tumor Classification through Fine-Tuned Vision Transformers: A Comparative Study of Pre-Trained Models},
  author={Asiri, A. A. and Shaf, A. and Ali, T. and Pasha, M. A. and Aamir, M. and Irfan, M. and Alqahtani, S. and Alghamdi, A. J. and Alghamdi, A. H. and Alshamrani, A. F. A. and Alelyani, M. and Alamri, S.},
  journal={Sensors (Basel, Switzerland)},
  volume={23},
  number={18},
  pages={7913},
  year={2023},
  doi={10.3390/s23187913}
}


% MobileNetV2 Use + Transfer Learning
@misc{surya2024enhancedbreastcancertumor,
      title={Enhanced Breast Cancer Tumor Classification using MobileNetV2: A Detailed Exploration on Image Intensity, Error Mitigation, and Streamlit-driven Real-time Deployment}, 
      author={Aaditya Surya and Aditya Shah and Jarnell Kabore and Subash Sasikumar},
      year={2024},
      eprint={2312.03020},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2312.03020}, 
}

% ViT-B/16
@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

% ViT-B/16
@misc{torchvision2024vitb16,
  author       = {PyTorch Team},
  title        = {Vision Transformer (ViT-B-16)},
  year         = {2024},
  howpublished = {\url{https://pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html}},
  note         = {Accessed: 2024-12-04}
}

% ViT-B/16
@misc{huggingface2024vitbase,
  author       = {Hugging Face},
  title        = {ViT Base Patch16-224 by Google},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/google/vit-base-patch16-224}},
  note         = {Accessed: 2024-12-04}
}

% PyToch Implementation
@misc{torchvision-vit,
  title = {Vision Transformer Implementation in TorchVision},
  author = {TorchVision Contributors},
  year = {2023},
  howpublished = {\url{https://github.com/pytorch/vision/blob/main/torchvision/models/vision_transformer.py}},
  note = {Accessed: 2024-12-18}
}


% ResNet50V2 proposed here
@misc{he2016identitymappingsdeepresidual,
      title={Identity Mappings in Deep Residual Networks}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2016},
      eprint={1603.05027},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1603.05027}, 
}

@misc{wightman2021resnetstrikesbackimproved,
      title={ResNet strikes back: An improved training procedure in timm}, 
      author={Ross Wightman and Hugo Touvron and Hervé Jégou},
      year={2021},
      eprint={2110.00476},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2110.00476}, 
}

% ResNet
@misc{he2015deepresiduallearningimage,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}

% ResNet50 PyTorch:
@misc{torchvision-resnet,
  title = {ResNet Implementation in TorchVision},
  author = {TorchVision Contributors},
  year = {2023},
  howpublished = {\url{https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py}},
  note = {Accessed: 2024-12-18}
}

% ResNet article
@misc{towardsdatascience_resnet,
  author       = {Sumit Saha},
  title        = {Review: ResNet — Winner of ILSVRC 2015 (Image Classification, Localization, Detection)},
  year         = {2018},
  url          = {https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8},
  note         = {Accessed: 2024-12-22}
}

% ResNet Transfer Learning
@article{RAZAVI2024123276,
title = {ResNet deep models and transfer learning technique for classification and quality detection of rice cultivars},
journal = {Expert Systems with Applications},
volume = {247},
pages = {123276},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123276},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424001416},
author = {Mohammad Razavi and Samira Mavaddati and Hamidreza Koohi},
}

% ResNet Transfer Learning
@InProceedings{resnettransfer,
author="Liu, Le
and Cheng, Jieren
and Xie, Luyi
and Song, Jinyang
and Zhou, Ke
and Liu, Jingxin",
editor="Tan, Ying
and Shi, Yuhui
and Zomaya, Albert
and Yan, Hongyang
and Cai, Jun",
title="A Transfer Learning Method Based on ResNet Model",
booktitle="Data Mining and Big Data",
year="2021",
publisher="Springer Singapore",
address="Singapore",
pages="250--260",
}

% Resnet Transfer Learning
@misc{chan2019transfer,
  author = {Chan, Kenneth},
  title = {A Guide to Transfer Learning with Keras Using ResNet50},
  year = {2019},
  url = {https://medium.com/@kenneth.ca95/a-guide-to-transfer-learning-with-keras-using-resnet50-a81a4a28084b},
  note = {Accessed: 2024-12-23}
}

% Resnet Transfer Learning
@misc{sinha2024transferlearning,
  author       = {Ritesh Sinha},
  title        = {Transfer Learning Using ResNet},
  year         = {2024},
  howpublished = {\url{https://www.kaggle.com/code/riteshsinha/transfer-learning-using-resnet}},
  note         = {Accessed: 2024-12-24}
}


% ResNet layers
@INPROCEEDINGS{10083966,
  author={Nagpal, Piyush and Bhinge, Shivani Atul and Shitole, Ajitkumar},
  booktitle={2022 International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)}, 
  title={A Comparative Analysis of ResNet Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/SMARTGENCON56628.2022.10083966}}

% ResNet Overview Blog
@misc{innovatiana_resnet50,
  author = {Innovatiana},
  title = {Discover ResNet-50},
  year = {2023},
  url = {https://en.innovatiana.com/post/discover-resnet-50},
  note = {Accessed: 2024-12-23}
}


% ResNet Usage
@Article{Shafiq2022,
AUTHOR = {Shafiq, Muhammad and Gu, Zhaoquan},
TITLE = {Deep Residual Learning for Image Recognition: A Survey},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {18},
ARTICLE-NUMBER = {8972},
URL = {https://www.mdpi.com/2076-3417/12/18/8972},
ISSN = {2076-3417},
DOI = {10.3390/app12188972}
}

% ResNet Medical Imaging
@misc{huang2022identifyingkeycomponentsresnet50,
      title={Identifying the key components in ResNet-50 for diabetic retinopathy grading from fundus images: a systematic investigation}, 
      author={Yijin Huang and Li Lin and Pujin Cheng and Junyan Lyu and Roger Tam and Xiaoying Tang},
      year={2022},
      eprint={2110.14160},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2110.14160}, 
}

@InProceedings{Simegn,
author="Simegn, Gizeaddis Lamesgin
and Degu, Mizanu Zelalem
and Tegenaw, Geletaw Sahle",
editor="Birhane, Abeba
and Shewarega, Fekadu
and Bitew, Mekuanint A.
and Wagaw, Mekonnen
and Abebe Ashetehe, Ahunim",
title="Cervical Cancer Histopathological Image Classification Using Imbalanced Domain Learning",
booktitle="Advancement of Science and Technology",
year="2025",
publisher="Springer Nature Switzerland",
address="Cham",
pages="3--20",
isbn="978-3-031-64151-0"
}

% ResNet-50 Flower Detection
@inproceedings{resnet_flower,
author = {Jaju, Sanay and Chandak, Manoj},
year = {2022},
month = {05},
pages = {307-311},
title = {A Transfer Learning Model Based on ResNet-50 for Flower Detection},
doi = {10.1109/ICAAIC53929.2022.9792697}
}

% Pest Detection
@INPROCEEDINGS{10112802,
  author={S, Umamaheswari and R, Vishal N and R, Pragadesh N and S, Lavanya},
  booktitle={2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={Performance Analysis of ResNet50 Architecture based Pest Detection System}, 
  year={2023},
  volume={1},
  number={},
  pages={578-583},
  doi={10.1109/ICACCS57279.2023.10112802}
}

% Face Detection
@INPROCEEDINGS{Nyarko2022,
  author={Esi Nyarko, Benedicta Nana and Bin, Wu and Zhou, Jinzhi and Agordzo, George K. and Odoom, Justice and Koukoyi, Ebenezer},
  booktitle={2022 IEEE World AI IoT Congress (AIIoT)}, 
  title={Comparative Analysis of AlexNet, Resnet-50, and Inception-V3 Models on Masked Face Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={337-343},
  doi={10.1109/AIIoT54504.2022.9817327}}


% ConvNeXt
@inproceedings{todi2023convnext,
  title={ConvNext: A Contemporary Architecture for Convolutional Neural Networks for Image Classification},
  author={Todi, Agastya and Narula, Navya and Sharma, Moolch and Gupta, Umesh},
  booktitle={2023 3rd International Conference on Innovative Sustainable Computational Technologies (CISCT)},
  pages={1--6},
  year={2023},
  organization={IEEE}
}

% ConvNet
@misc{liu2022convnet2020s,
      title={A ConvNet for the 2020s}, 
      author={Zhuang Liu and Hanzi Mao and Chao-Yuan Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie},
      year={2022},
      eprint={2201.03545},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.03545}, 
}

% ConvNeXt Base
@misc{torchvision2024convnextbase,
  author       = {PyTorch Team},
  title        = {ConvNeXt Base Model},
  year         = {2024},
  howpublished = {\url{https://pytorch.org/vision/main/models/generated/torchvision.models.convnext_base.html}},
  note         = {Accessed: 2024-12-04}
}



% ConvNext Implementation
@misc{torchvision-convnext,
  title = {ConvNeXt Implementation in TorchVision},
  author = {TorchVision Contributors},
  year = {2023},
  howpublished = {\url{https://github.com/pytorch/vision/blob/main/torchvision/models/convnext.py}},
  note = {Accessed: 2024-12-18}
}

% ResNeXt
@misc{xie2017aggregatedresidualtransformationsdeep,
      title={Aggregated Residual Transformations for Deep Neural Networks}, 
      author={Saining Xie and Ross Girshick and Piotr Dollár and Zhuowen Tu and Kaiming He},
      year={2017},
      eprint={1611.05431},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1611.05431}, 
}

% EfficientNet
@misc{tan2020efficientnetrethinkingmodelscaling,
      title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}, 
      author={Mingxing Tan and Quoc V. Le},
      year={2020},
      eprint={1905.11946},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1905.11946}, 
}

% Transfer Learning on large datasets
@misc{kolesnikov2020bigtransferbitgeneral,
      title={Big Transfer (BiT): General Visual Representation Learning}, 
      author={Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Joan Puigcerver and Jessica Yung and Sylvain Gelly and Neil Houlsby},
      year={2020},
      eprint={1912.11370},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1912.11370}, 
}

% Fine-tuning
@misc{ye2023partialfinetuningsuccessorfinetuning,
      title={Partial Fine-Tuning: A Successor to Full Fine-Tuning for Vision Transformers}, 
      author={Peng Ye and Yongqi Huang and Chongjun Tu and Minglei Li and Tao Chen and Tong He and Wanli Ouyang},
      year={2023},
      eprint={2312.15681},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.15681}, 
}

% Transfer Learning
@Article{kandel2020,
AUTHOR = {Kandel, Ibrahem and Castelli, Mauro},
TITLE = {How Deeply to Fine-Tune a Convolutional Neural Network: A Case Study Using a Histopathology Dataset},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {3359},
URL = {https://www.mdpi.com/2076-3417/10/10/3359},
ISSN = {2076-3417},
DOI = {10.3390/app10103359}
}

% Transfer Learning
@misc{yosinski2014transferablefeaturesdeepneural,
      title={How transferable are features in deep neural networks?}, 
      author={Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
      year={2014},
      eprint={1411.1792},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1411.1792}, 
}
% ===============================================================================
% Convolutional Neural Network references

@inproceedings{lecun1995,
author = {Lecun, Yann and Jackel, Larry and Bottou, L. and Brunot, A. and Cortes, Corinna and Denker, John and Drucker, Harris and Guyon, Isabelle and Muller, Urs and Sackinger, E. and Simard, Patrice and Vapnik, V.},
year = {1995},
month = {01},
pages = {},
title = {Comparison of learning algorithms for handwritten digit recognition},
journal = {International Conference on Artificial Neural Networks}
}

@ARTICLE{lecun1998,
  author={LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  journal={Neural Computation}, 
  title={Backpropagation Applied to Handwritten Zip Code Recognition}, 
  year={1989},
  volume={1},
  number={4},
  pages={541-551},
  keywords={},
  doi={10.1162/neco.1989.1.4.541}}



@misc{mathworks_cnn,
  title        = {What Is a Convolutional Neural Network?},
  howpublished = {MathWorks, [Online]},
  note         = {Available: \url{https://www.mathworks.com/discovery/convolutional-neural-network.html}. Accessed: 28-Nov-2024},
}

% AlexNet
@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

% VGGNet
@misc{simonyan2015deepconvolutionalnetworkslargescale,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

% GoogLeNet
@misc{szegedy2014goingdeeperconvolutions,
      title={Going Deeper with Convolutions}, 
      author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
      year={2014},
      eprint={1409.4842},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.4842}, 
}
% ===============================================================================
% Vision Transformer references

@misc{raghu2022visiontransformerslikeconvolutional,
      title={Do Vision Transformers See Like Convolutional Neural Networks?}, 
      author={Maithra Raghu and Thomas Unterthiner and Simon Kornblith and Chiyuan Zhang and Alexey Dosovitskiy},
      year={2022},
      eprint={2108.08810},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2108.08810}, 
}

% Transformer
@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

% Guide
@misc{v7labs-vit,
  title = {Vision Transformer Guide},
  author = {V7 Labs},
  year = {2024},
  howpublished = {\url{https://www.v7labs.com/blog/vision-transformer-guide}},
  note = {Accessed: 2024-12-18}
}


% ===============================================================================
% GitHub Repositories

% Deep Long-Tailed Learning: A Survey
@misc{VanintLT,
  author = {Vanint},
  title = {Awesome-LongTailed-Learning},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Vanint/Awesome-LongTailed-Learning}},
  commit = {2269dfe0e2bf4d6d4b88eb414614ecd1738bfc67},
  note = {Accessed: 2024-09-18}
}

% LDAM-DRW
@misc{kaidic_ldam_drw,
  author       = {Kai, Di},
  title        = {LDAM-DRW: Learning from Long-Tailed Data},
  howpublished = {GitHub repository, [Online]},
  note         = {Available: \url{https://github.com/kaidic/LDAM-DRW/tree/master}. Accessed: 2024-09-18},
}


% ===============================================================================
% Optimizers

@misc{choi2020empiricalcomparisonsoptimizersdeep,
      title={On Empirical Comparisons of Optimizers for Deep Learning}, 
      author={Dami Choi and Christopher J. Shallue and Zachary Nado and Jaehoon Lee and Chris J. Maddison and George E. Dahl},
      year={2020},
      eprint={1910.05446},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.05446}, 
}


@misc{pytorch_steplr,
  author = {PyTorch Te<m},
  howpublished = {\url{https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html}},
  title = {StepLR},
  year = {2024}
}

@misc{
loshchilov2018fixing,
title={Fixing Weight Decay Regularization in Adam},
author={Ilya Loshchilov and Frank Hutter},
year={2018},
url={https://openreview.net/forum?id=rk6qdGgCZ},
}

Adam
@misc{kingma2017adammethodstochasticoptimization,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

% ===============================================================================
% Benchmarks

% Mobilenetv2
@misc{wang2019e2traintrainingstateoftheartcnns,
      title={E2-Train: Training State-of-the-art CNNs with Over 80% Energy Savings}, 
      author={Yue Wang and Ziyu Jiang and Xiaohan Chen and Pengfei Xu and Yang Zhao and Yingyan Lin and Zhangyang Wang},
      year={2019},
      eprint={1910.13349},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.13349}, 
}

@misc{park2022bitatneuralnetworkbinarization,
      title={BiTAT: Neural Network Binarization with Task-dependent Aggregated Transformation}, 
      author={Geon Park and Jaehong Yoon and Haiyang Zhang and Xing Zhang and Sung Ju Hwang and Yonina C. Eldar},
      year={2022},
      eprint={2207.01394},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2207.01394}, 
}


% ViT-B/16
@inproceedings{Tseng_2022,
   title={Perturbed Gradients Updating within Unit Space for Deep Learning},
   url={http://dx.doi.org/10.1109/IJCNN55064.2022.9892245},
   DOI={10.1109/ijcnn55064.2022.9892245},
   booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
   publisher={IEEE},
   author={Tseng, Ching-Hsun and Liu, Hsueh-Cheng and Lee, Shin-Jye and Zeng, Xiaojun},
   year={2022},
   month=jul, pages={01-08} }

% Conv2NeXt
@INPROCEEDINGS{10072172,
  author={Feng, Jianwei and Tan, Hengliang and Li, Wangwang and Xie, Ming},
  booktitle={2022 International Conference on Computers and Artificial Intelligence Technologies (CAIT)}, 
  title={Conv2NeXt: Reconsidering Conv NeXt Network Design for Image Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={53-60},
  doi={10.1109/CAIT56099.2022.10072172}}


% ===============================================================================
% Related Work

% Re-sampling, SMOTE
@article{Chawla_2002,
   title={SMOTE: Synthetic Minority Over-sampling Technique},
   volume={16},
   ISSN={1076-9757},
   url={http://dx.doi.org/10.1613/jair.953},
   DOI={10.1613/jair.953},
   journal={Journal of Artificial Intelligence Research},
   publisher={AI Access Foundation},
   author={Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
   year={2002},
   month=jun, pages={321-357} }

@inproceedings{han2005,
      author = {Han, Hui and Wang, Wen-Yuan and Mao, Bing-Huan},
      title = {Borderline-SMOTE: a new over-sampling method in imbalanced data sets learning},
      year = {2005},
      isbn = {3540282262},
      publisher = {Springer-Verlag},
      address = {Berlin, Heidelberg},
      url = {https://doi.org/10.1007/11538059_91},
      doi = {10.1007/11538059_91},
      booktitle = {Proceedings of the 2005 International Conference on Advances in Intelligent Computing - Volume Part I},
      pages = {878–887},
      numpages = {10},
      location = {Hefei, China},
      series = {ICIC'05}
}

% Few-Shot Learning
@misc{wang2020generalizingexamplessurveyfewshot,
      title={Generalizing from a Few Examples: A Survey on Few-Shot Learning}, 
      author={Yaqing Wang and Quanming Yao and James Kwok and Lionel M. Ni},
      year={2020},
      eprint={1904.05046},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1904.05046}, 
}

% Logit Adjustment
@misc{menon2021longtaillearninglogitadjustment,
      title={Long-tail learning via logit adjustment}, 
      author={Aditya Krishna Menon and Sadeep Jayasumana and Ankit Singh Rawat and Himanshu Jain and Andreas Veit and Sanjiv Kumar},
      year={2021},
      eprint={2007.07314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.07314}, 
}

% Survey
@misc{zhang2024systematicreviewlongtailedlearning,
      title={A Systematic Review on Long-Tailed Learning}, 
      author={Chongsheng Zhang and George Almpanidis and Gaojuan Fan and Binquan Deng and Yanbo Zhang and Ji Liu and Aouaidjia Kamel and Paolo Soda and João Gama},
      year={2024},
      eprint={2408.00483},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.00483}, 
}

% Data Augmentation
@misc{perez2017effectivenessdataaugmentationimage,
      title={The Effectiveness of Data Augmentation in Image Classification using Deep Learning}, 
      author={Luis Perez and Jason Wang},
      year={2017},
      eprint={1712.04621},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1712.04621}, 
}

% Data Augmentation
@article{shorten2019survey,
  title={A survey on image data augmentation for deep learning},
  author={Shorten, Connor and Khoshgoftaar, Taghi M.},
  journal={Journal of Big Data},
  volume={6},
  number={1},
  pages={1--48},
  year={2019},
  publisher={Springer}
}

% CutMix
@misc{yun2019cutmixregularizationstrategytrain,
      title={CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features}, 
      author={Sangdoo Yun and Dongyoon Han and Seong Joon Oh and Sanghyuk Chun and Junsuk Choe and Youngjoon Yoo},
      year={2019},
      eprint={1905.04899},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1905.04899}, 
}

% MixUp
@misc{zhang2018mixupempiricalriskminimization,
      title={mixup: Beyond Empirical Risk Minimization}, 
      author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
      year={2018},
      eprint={1710.09412},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1710.09412}, 
}

% RandAugment
@misc{cubuk2019randaugmentpracticalautomateddata,
      title={RandAugment: Practical automated data augmentation with a reduced search space}, 
      author={Ekin D. Cubuk and Barret Zoph and Jonathon Shlens and Quoc V. Le},
      year={2019},
      eprint={1909.13719},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1909.13719}, 
}

% UniMix
@misc{xu2021calibratedmodellongtailedvisual,
      title={Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective}, 
      author={Zhengzhuo Xu and Zenghao Chai and Chun Yuan},
      year={2021},
      eprint={2111.03874},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2111.03874}, 
}

% MiSLAS
@misc{zhong2021improvingcalibrationlongtailedrecognition,
      title={Improving Calibration for Long-Tailed Recognition}, 
      author={Zhisheng Zhong and Jiequan Cui and Shu Liu and Jiaya Jia},
      year={2021},
      eprint={2104.00466},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2104.00466}, 
}

% RSG
@misc{wang2021rsgsimpleeffectivemodule,
      title={RSG: A Simple but Effective Module for Learning Imbalanced Datasets}, 
      author={Jianfeng Wang and Thomas Lukasiewicz and Xiaolin Hu and Jianfei Cai and Zhenghua Xu},
      year={2021},
      eprint={2106.09859},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2106.09859}, 
}

% Decoupling
@misc{kang2020decouplingrepresentationclassifierlongtailed,
      title={Decoupling Representation and Classifier for Long-Tailed Recognition}, 
      author={Bingyi Kang and Saining Xie and Marcus Rohrbach and Zhicheng Yan and Albert Gordo and Jiashi Feng and Yannis Kalantidis},
      year={2020},
      eprint={1910.09217},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1910.09217}, 
}

% Transfer Learning
@misc{yin2019featuretransferlearningdeep,
      title={Feature Transfer Learning for Deep Face Recognition with Under-Represented Data}, 
      author={Xi Yin and Xiang Yu and Kihyuk Sohn and Xiaoming Liu and Manmohan Chandraker},
      year={2019},
      eprint={1803.09014},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1803.09014}, 
}

% Transfer Learning
@ARTICLE{pan2010,
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Transfer Learning}, 
  year={2010},
  volume={22},
  number={10},
  pages={1345-1359},
  doi={10.1109/TKDE.2009.191}
  }

% Transfer Learning

@article{Hinton2006,
author = {G. E. Hinton  and R. R. Salakhutdinov },
title = {Reducing the Dimensionality of Data with Neural Networks},
journal = {Science},
volume = {313},
number = {5786},
pages = {504-507},
year = {2006},
doi = {10.1126/science.1127647},
URL = {https://www.science.org/doi/abs/10.1126/science.1127647},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1127647},
}

@inproceedings{Fu2021,
author = {Fu, Yang and Huang, Xiangnian and Li, Yunfeng},
title = {Horse Breed Classification Based on Transfer Learning},
year = {2021},
isbn = {9781450388368},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3441250.3441264},
doi = {10.1145/3441250.3441264},
booktitle = {Proceedings of the 4th International Conference on Advances in Image Processing},
pages = {42–47},
numpages = {6},
keywords = {Transfer Learning, MobilenetV2, Horse Breed Classification, Convolutional Neural Network},
location = {Chengdu, China},
series = {ICAIP '20}
}


% Ensemble Learning
@misc{zhou2020bbnbilateralbranchnetworkcumulative,
      title={BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition}, 
      author={Boyan Zhou and Quan Cui and Xiu-Shen Wei and Zhao-Min Chen},
      year={2020},
      eprint={1912.02413},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1912.02413}, 
}

@misc{wang2022longtailedrecognitionroutingdiverse,
      title={Long-tailed Recognition by Routing Diverse Distribution-Aware Experts}, 
      author={Xudong Wang and Long Lian and Zhongqi Miao and Ziwei Liu and Stella X. Yu},
      year={2022},
      eprint={2010.01809},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.01809}, 
}
%=================================================================================
% PyTorch

@misc{paszke2019pytorchimperativestylehighperformance,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.01703}, 
}